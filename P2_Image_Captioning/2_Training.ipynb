{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision Nanodegree\n",
    "\n",
    "## Project: Image Captioning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will train your CNN-RNN model.  \n",
    "\n",
    "You are welcome and encouraged to try out many different architectures and hyperparameters when searching for a good model.\n",
    "\n",
    "This does have the potential to make the project quite messy!  Before submitting your project, make sure that you clean up:\n",
    "- the code you write in this notebook.  The notebook should describe how to train a single CNN-RNN architecture, corresponding to your final choice of hyperparameters.  You should structure the notebook so that the reviewer can replicate your results by running the code in this notebook.  \n",
    "- the output of the code cell in **Step 2**.  The output should show the output obtained when training the model from scratch.\n",
    "\n",
    "This notebook **will be graded**.  \n",
    "\n",
    "Feel free to use the links below to navigate the notebook:\n",
    "- [Step 1](#step1): Training Setup\n",
    "- [Step 2](#step2): Train your Model\n",
    "- [Step 3](#step3): (Optional) Validate your Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step1'></a>\n",
    "## Step 1: Training Setup\n",
    "\n",
    "In this step of the notebook, you will customize the training of your CNN-RNN model by specifying hyperparameters and setting other options that are important to the training procedure.  The values you set now will be used when training your model in **Step 2** below.\n",
    "\n",
    "You should only amend blocks of code that are preceded by a `TODO` statement.  **Any code blocks that are not preceded by a `TODO` statement should not be modified**.\n",
    "\n",
    "### Task #1\n",
    "\n",
    "Begin by setting the following variables:\n",
    "- `batch_size` - the batch size of each training batch.  It is the number of image-caption pairs used to amend the model weights in each training step. \n",
    "- `vocab_threshold` - the minimum word count threshold.  Note that a larger threshold will result in a smaller vocabulary, whereas a smaller threshold will include rarer words and result in a larger vocabulary.  \n",
    "- `vocab_from_file` - a Boolean that decides whether to load the vocabulary from file. \n",
    "- `embed_size` - the dimensionality of the image and word embeddings.  \n",
    "- `hidden_size` - the number of features in the hidden state of the RNN decoder.  \n",
    "- `num_epochs` - the number of epochs to train the model.  We recommend that you set `num_epochs=3`, but feel free to increase or decrease this number as you wish.  [This paper](https://arxiv.org/pdf/1502.03044.pdf) trained a captioning model on a single state-of-the-art GPU for 3 days, but you'll soon see that you can get reasonable results in a matter of a few hours!  (_But of course, if you want your model to compete with current research, you will have to train for much longer._)\n",
    "- `save_every` - determines how often to save the model weights.  We recommend that you set `save_every=1`, to save the model weights after each epoch.  This way, after the `i`th epoch, the encoder and decoder weights will be saved in the `models/` folder as `encoder-i.pkl` and `decoder-i.pkl`, respectively.\n",
    "- `print_every` - determines how often to print the batch loss to the Jupyter notebook while training.  Note that you **will not** observe a monotonic decrease in the loss function while training - this is perfectly fine and completely expected!  You are encouraged to keep this at its default value of `100` to avoid clogging the notebook, but feel free to change it.\n",
    "- `log_file` - the name of the text file containing - for every step - how the loss and perplexity evolved during training.\n",
    "\n",
    "If you're not sure where to begin to set some of the values above, you can peruse [this paper](https://arxiv.org/pdf/1502.03044.pdf) and [this paper](https://arxiv.org/pdf/1411.4555.pdf) for useful guidance!  **To avoid spending too long on this notebook**, you are encouraged to consult these suggested research papers to obtain a strong initial guess for which hyperparameters are likely to work best.  Then, train a single model, and proceed to the next notebook (**3_Inference.ipynb**).  If you are unhappy with your performance, you can return to this notebook to tweak the hyperparameters (and/or the architecture in **model.py**) and re-train your model.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "**Question:** Describe your CNN-RNN architecture in detail.  With this architecture in mind, how did you select the values of the variables in Task 1?  If you consulted a research paper detailing a successful implementation of an image captioning model, please provide the reference.\n",
    "\n",
    "I'm using ResNet 50 architecture and LSTM layers for the RNN. I'm using 512 dimensions for the embeddings and the size of the LSTM memory as well as 5 for the threshold as mentioned in the paper.\n",
    "\n",
    "\n",
    "### (Optional) Task #2\n",
    "\n",
    "Note that we have provided a recommended image transform `transform_train` for pre-processing the training images, but you are welcome (and encouraged!) to modify it as you wish.  When modifying this transform, keep in mind that:\n",
    "- the images in the dataset have varying heights and widths, and \n",
    "- if using a pre-trained model, you must perform the corresponding appropriate normalization.\n",
    "\n",
    "### Question 2\n",
    "\n",
    "**Question:** How did you select the transform in `transform_train`?  If you left the transform at its provided value, why do you think that it is a good choice for your CNN architecture?\n",
    "\n",
    "I have left the values as it is\n",
    "\n",
    "### Task #3\n",
    "\n",
    "Next, you will specify a Python list containing the learnable parameters of the model.  For instance, if you decide to make all weights in the decoder trainable, but only want to train the weights in the embedding layer of the encoder, then you should set `params` to something like:\n",
    "```\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters()) \n",
    "```\n",
    "\n",
    "### Question 3\n",
    "\n",
    "**Question:** How did you select the trainable parameters of your architecture?  Why do you think this is a good choice?\n",
    "\n",
    "(I'm not 100% sure) Since we're using transfer learning on ResNet, we need to learn the embedding layer to extract the features that are desirable for the input of the RNN. As for the RNN side, we need to learn everything since that's what'll result in the output\n",
    "\n",
    "### Task #4\n",
    "\n",
    "Finally, you will select an [optimizer](http://pytorch.org/docs/master/optim.html#torch.optim.Optimizer).\n",
    "\n",
    "### Question 4\n",
    "\n",
    "**Question:** How did you select the optimizer used to train your model?\n",
    "\n",
    "I used Adam because it's a commonly used optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/414113 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 430/414113 [00:00<01:36, 4295.60it/s]\u001b[A\n",
      "  0%|          | 837/414113 [00:00<01:37, 4222.11it/s]\u001b[A\n",
      "  0%|          | 1305/414113 [00:00<01:34, 4349.23it/s]\u001b[A\n",
      "  0%|          | 1772/414113 [00:00<01:32, 4439.42it/s]\u001b[A\n",
      "  1%|          | 2233/414113 [00:00<01:31, 4488.42it/s]\u001b[A\n",
      "  1%|          | 2697/414113 [00:00<01:30, 4529.86it/s]\u001b[A\n",
      "  1%|          | 3150/414113 [00:00<01:30, 4529.44it/s]\u001b[A\n",
      "  1%|          | 3633/414113 [00:00<01:28, 4613.22it/s]\u001b[A\n",
      "  1%|          | 4106/414113 [00:00<01:28, 4645.20it/s]\u001b[A\n",
      "  1%|          | 4589/414113 [00:01<01:27, 4696.89it/s]\u001b[A\n",
      "  1%|          | 5063/414113 [00:01<01:26, 4708.06it/s]\u001b[A\n",
      "  1%|▏         | 5538/414113 [00:01<01:26, 4717.38it/s]\u001b[A\n",
      "  1%|▏         | 6014/414113 [00:01<01:26, 4728.48it/s]\u001b[A\n",
      "  2%|▏         | 6483/414113 [00:01<01:26, 4710.94it/s]\u001b[A\n",
      "  2%|▏         | 6952/414113 [00:01<01:26, 4693.95it/s]\u001b[A\n",
      "  2%|▏         | 7420/414113 [00:01<01:27, 4672.99it/s]\u001b[A\n",
      "  2%|▏         | 7897/414113 [00:01<01:26, 4700.95it/s]\u001b[A\n",
      "  2%|▏         | 8375/414113 [00:01<01:25, 4724.11it/s]\u001b[A\n",
      "  2%|▏         | 8852/414113 [00:01<01:25, 4736.30it/s]\u001b[A\n",
      "  2%|▏         | 9326/414113 [00:02<01:25, 4710.15it/s]\u001b[A\n",
      "  2%|▏         | 9797/414113 [00:02<01:26, 4679.01it/s]\u001b[A\n",
      "  2%|▏         | 10267/414113 [00:02<01:26, 4684.88it/s]\u001b[A\n",
      "  3%|▎         | 10738/414113 [00:02<01:26, 4689.65it/s]\u001b[A\n",
      "  3%|▎         | 11207/414113 [00:02<01:26, 4669.05it/s]\u001b[A\n",
      "  3%|▎         | 11676/414113 [00:02<01:26, 4674.98it/s]\u001b[A\n",
      "  3%|▎         | 12144/414113 [00:02<01:26, 4673.46it/s]\u001b[A\n",
      "  3%|▎         | 12612/414113 [00:02<01:26, 4655.08it/s]\u001b[A\n",
      "  3%|▎         | 13095/414113 [00:02<01:25, 4704.57it/s]\u001b[A\n",
      "  3%|▎         | 13569/414113 [00:02<01:24, 4715.09it/s]\u001b[A\n",
      "  3%|▎         | 14042/414113 [00:03<01:24, 4718.95it/s]\u001b[A\n",
      "  4%|▎         | 14522/414113 [00:03<01:24, 4740.96it/s]\u001b[A\n",
      "  4%|▎         | 14997/414113 [00:03<01:24, 4713.35it/s]\u001b[A\n",
      "  4%|▎         | 15479/414113 [00:03<01:24, 4743.21it/s]\u001b[A\n",
      "  4%|▍         | 15954/414113 [00:03<01:23, 4743.29it/s]\u001b[A\n",
      "  4%|▍         | 16429/414113 [00:03<01:24, 4721.62it/s]\u001b[A\n",
      "  4%|▍         | 16912/414113 [00:03<01:23, 4751.88it/s]\u001b[A\n",
      "  4%|▍         | 17389/414113 [00:03<01:23, 4755.65it/s]\u001b[A\n",
      "  4%|▍         | 17865/414113 [00:03<01:23, 4752.47it/s]\u001b[A\n",
      "  4%|▍         | 18351/414113 [00:03<01:22, 4782.76it/s]\u001b[A\n",
      "  5%|▍         | 18830/414113 [00:04<01:22, 4775.49it/s]\u001b[A\n",
      "  5%|▍         | 19314/414113 [00:04<01:22, 4792.95it/s]\u001b[A\n",
      "  5%|▍         | 19798/414113 [00:04<01:22, 4805.82it/s]\u001b[A\n",
      "  5%|▍         | 20279/414113 [00:04<01:22, 4769.48it/s]\u001b[A\n",
      "  5%|▌         | 20757/414113 [00:04<01:22, 4751.51it/s]\u001b[A\n",
      "  5%|▌         | 21233/414113 [00:04<01:22, 4740.54it/s]\u001b[A\n",
      "  5%|▌         | 21715/414113 [00:04<01:22, 4761.92it/s]\u001b[A\n",
      "  5%|▌         | 22192/414113 [00:04<01:22, 4748.89it/s]\u001b[A\n",
      "  5%|▌         | 22675/414113 [00:04<01:22, 4772.84it/s]\u001b[A\n",
      "  6%|▌         | 23164/414113 [00:04<01:21, 4807.34it/s]\u001b[A\n",
      "  6%|▌         | 23645/414113 [00:05<01:21, 4788.62it/s]\u001b[A\n",
      "  6%|▌         | 24124/414113 [00:05<01:22, 4709.31it/s]\u001b[A\n",
      "  6%|▌         | 24604/414113 [00:05<01:22, 4735.05it/s]\u001b[A\n",
      "  6%|▌         | 25080/414113 [00:05<01:22, 4741.62it/s]\u001b[A\n",
      "  6%|▌         | 25555/414113 [00:05<01:22, 4724.55it/s]\u001b[A\n",
      "  6%|▋         | 26029/414113 [00:05<01:22, 4727.42it/s]\u001b[A\n",
      "  6%|▋         | 26512/414113 [00:05<01:21, 4755.69it/s]\u001b[A\n",
      "  7%|▋         | 26990/414113 [00:05<01:21, 4759.59it/s]\u001b[A\n",
      "  7%|▋         | 27467/414113 [00:05<01:22, 4697.55it/s]\u001b[A\n",
      "  7%|▋         | 27937/414113 [00:05<01:24, 4562.97it/s]\u001b[A\n",
      "  7%|▋         | 28403/414113 [00:06<01:24, 4591.52it/s]\u001b[A\n",
      "  7%|▋         | 28886/414113 [00:06<01:22, 4659.70it/s]\u001b[A\n",
      "  7%|▋         | 29359/414113 [00:06<01:22, 4680.25it/s]\u001b[A\n",
      "  7%|▋         | 29851/414113 [00:06<01:20, 4747.13it/s]\u001b[A\n",
      "  7%|▋         | 30327/414113 [00:06<01:20, 4740.37it/s]\u001b[A\n",
      "  7%|▋         | 30802/414113 [00:06<01:21, 4726.54it/s]\u001b[A\n",
      "  8%|▊         | 31296/414113 [00:06<01:19, 4786.98it/s]\u001b[A\n",
      "  8%|▊         | 31778/414113 [00:06<01:19, 4795.07it/s]\u001b[A\n",
      "  8%|▊         | 32267/414113 [00:06<01:19, 4822.50it/s]\u001b[A\n",
      "  8%|▊         | 32750/414113 [00:06<01:19, 4771.79it/s]\u001b[A\n",
      "  8%|▊         | 33234/414113 [00:07<01:19, 4789.24it/s]\u001b[A\n",
      "  8%|▊         | 33714/414113 [00:07<01:20, 4753.98it/s]\u001b[A\n",
      "  8%|▊         | 34194/414113 [00:07<01:19, 4765.94it/s]\u001b[A\n",
      "  8%|▊         | 34671/414113 [00:07<01:20, 4740.47it/s]\u001b[A\n",
      "  8%|▊         | 35146/414113 [00:07<01:20, 4720.31it/s]\u001b[A\n",
      "  9%|▊         | 35621/414113 [00:07<01:20, 4726.09it/s]\u001b[A\n",
      "  9%|▊         | 36094/414113 [00:07<01:19, 4725.65it/s]\u001b[A\n",
      "  9%|▉         | 36577/414113 [00:07<01:19, 4756.41it/s]\u001b[A\n",
      "  9%|▉         | 37062/414113 [00:07<01:18, 4783.20it/s]\u001b[A\n",
      "  9%|▉         | 37546/414113 [00:07<01:18, 4798.52it/s]\u001b[A\n",
      "  9%|▉         | 38028/414113 [00:08<01:18, 4802.56it/s]\u001b[A\n",
      "  9%|▉         | 38509/414113 [00:08<01:18, 4770.19it/s]\u001b[A\n",
      "  9%|▉         | 38998/414113 [00:08<01:18, 4803.78it/s]\u001b[A\n",
      " 10%|▉         | 39479/414113 [00:08<01:18, 4765.21it/s]\u001b[A\n",
      " 10%|▉         | 39960/414113 [00:08<01:18, 4776.77it/s]\u001b[A\n",
      " 10%|▉         | 40438/414113 [00:08<01:18, 4764.49it/s]\u001b[A\n",
      " 10%|▉         | 40916/414113 [00:08<01:18, 4767.04it/s]\u001b[A\n",
      " 10%|▉         | 41401/414113 [00:08<01:17, 4791.02it/s]\u001b[A\n",
      " 10%|█         | 41881/414113 [00:08<01:21, 4563.71it/s]\u001b[A\n",
      " 10%|█         | 42353/414113 [00:08<01:20, 4607.85it/s]\u001b[A\n",
      " 10%|█         | 42816/414113 [00:09<01:20, 4605.18it/s]\u001b[A\n",
      " 10%|█         | 43305/414113 [00:09<01:19, 4685.17it/s]\u001b[A\n",
      " 11%|█         | 43788/414113 [00:09<01:18, 4725.28it/s]\u001b[A\n",
      " 11%|█         | 44263/414113 [00:09<01:18, 4732.09it/s]\u001b[A\n",
      " 11%|█         | 44737/414113 [00:09<01:18, 4731.93it/s]\u001b[A\n",
      " 11%|█         | 45226/414113 [00:09<01:17, 4777.48it/s]\u001b[A\n",
      " 11%|█         | 45707/414113 [00:09<01:16, 4785.85it/s]\u001b[A\n",
      " 11%|█         | 46194/414113 [00:09<01:16, 4808.51it/s]\u001b[A\n",
      " 11%|█▏        | 46676/414113 [00:09<01:16, 4781.93it/s]\u001b[A\n",
      " 11%|█▏        | 47160/414113 [00:09<01:16, 4795.92it/s]\u001b[A\n",
      " 12%|█▏        | 47640/414113 [00:10<01:16, 4769.82it/s]\u001b[A\n",
      " 12%|█▏        | 48118/414113 [00:10<01:16, 4759.37it/s]\u001b[A\n",
      " 12%|█▏        | 48595/414113 [00:10<01:17, 4743.36it/s]\u001b[A\n",
      " 12%|█▏        | 49070/414113 [00:10<01:17, 4696.87it/s]\u001b[A\n",
      " 12%|█▏        | 49540/414113 [00:10<01:17, 4684.85it/s]\u001b[A\n",
      " 12%|█▏        | 50016/414113 [00:10<01:17, 4705.23it/s]\u001b[A\n",
      " 12%|█▏        | 50493/414113 [00:10<01:16, 4724.17it/s]\u001b[A\n",
      " 12%|█▏        | 50966/414113 [00:10<01:17, 4701.85it/s]\u001b[A\n",
      " 12%|█▏        | 51440/414113 [00:10<01:16, 4711.70it/s]\u001b[A\n",
      " 13%|█▎        | 51923/414113 [00:10<01:16, 4743.77it/s]\u001b[A\n",
      " 13%|█▎        | 52398/414113 [00:11<01:16, 4740.77it/s]\u001b[A\n",
      " 13%|█▎        | 52875/414113 [00:11<01:16, 4746.61it/s]\u001b[A\n",
      " 13%|█▎        | 53366/414113 [00:11<01:15, 4792.79it/s]\u001b[A\n",
      " 13%|█▎        | 53846/414113 [00:11<01:15, 4782.24it/s]\u001b[A\n",
      " 13%|█▎        | 54325/414113 [00:11<01:15, 4764.61it/s]\u001b[A\n",
      " 13%|█▎        | 54802/414113 [00:11<01:15, 4760.11it/s]\u001b[A\n",
      " 13%|█▎        | 55282/414113 [00:11<01:15, 4771.53it/s]\u001b[A\n",
      " 13%|█▎        | 55760/414113 [00:11<01:15, 4769.85it/s]\u001b[A\n",
      " 14%|█▎        | 56240/414113 [00:11<01:14, 4776.77it/s]\u001b[A\n",
      " 14%|█▎        | 56727/414113 [00:12<01:14, 4803.88it/s]\u001b[A\n",
      " 14%|█▍        | 57208/414113 [00:12<01:14, 4800.66it/s]\u001b[A\n",
      " 14%|█▍        | 57689/414113 [00:12<01:14, 4794.08it/s]\u001b[A\n",
      " 14%|█▍        | 58169/414113 [00:12<01:14, 4792.32it/s]\u001b[A\n",
      " 14%|█▍        | 58649/414113 [00:12<01:14, 4758.10it/s]\u001b[A\n",
      " 14%|█▍        | 59125/414113 [00:12<01:14, 4743.79it/s]\u001b[A\n",
      " 14%|█▍        | 59600/414113 [00:12<01:14, 4731.71it/s]\u001b[A\n",
      " 15%|█▍        | 60076/414113 [00:12<01:14, 4740.14it/s]\u001b[A\n",
      " 15%|█▍        | 60560/414113 [00:12<01:14, 4769.40it/s]\u001b[A\n",
      " 15%|█▍        | 61045/414113 [00:12<01:13, 4792.56it/s]\u001b[A\n",
      " 15%|█▍        | 61526/414113 [00:13<01:13, 4796.69it/s]\u001b[A\n",
      " 15%|█▍        | 62006/414113 [00:13<01:14, 4751.10it/s]\u001b[A\n",
      " 15%|█▌        | 62482/414113 [00:13<01:14, 4693.75it/s]\u001b[A\n",
      " 15%|█▌        | 62966/414113 [00:13<01:14, 4736.30it/s]\u001b[A\n",
      " 15%|█▌        | 63446/414113 [00:13<01:13, 4754.28it/s]\u001b[A\n",
      " 15%|█▌        | 63927/414113 [00:13<01:13, 4768.57it/s]\u001b[A\n",
      " 16%|█▌        | 64405/414113 [00:13<01:13, 4764.73it/s]\u001b[A\n",
      " 16%|█▌        | 64888/414113 [00:13<01:13, 4782.36it/s]\u001b[A\n",
      " 16%|█▌        | 65367/414113 [00:13<01:13, 4736.38it/s]\u001b[A\n",
      " 16%|█▌        | 65858/414113 [00:13<01:12, 4785.28it/s]\u001b[A\n",
      " 16%|█▌        | 66337/414113 [00:14<01:12, 4775.79it/s]\u001b[A\n",
      " 16%|█▌        | 66818/414113 [00:14<01:12, 4785.17it/s]\u001b[A\n",
      " 16%|█▋        | 67297/414113 [00:14<01:12, 4757.17it/s]\u001b[A\n",
      " 16%|█▋        | 67773/414113 [00:14<01:13, 4718.02it/s]\u001b[A\n",
      " 16%|█▋        | 68245/414113 [00:14<01:55, 2982.63it/s]\u001b[A\n",
      " 17%|█▋        | 68714/414113 [00:14<01:43, 3347.39it/s]\u001b[A\n",
      " 17%|█▋        | 69189/414113 [00:14<01:33, 3672.25it/s]\u001b[A\n",
      " 17%|█▋        | 69672/414113 [00:14<01:27, 3955.35it/s]\u001b[A\n",
      " 17%|█▋        | 70162/414113 [00:15<01:21, 4197.78it/s]\u001b[A\n",
      " 17%|█▋        | 70651/414113 [00:15<01:18, 4381.42it/s]\u001b[A\n",
      " 17%|█▋        | 71126/414113 [00:15<01:16, 4484.41it/s]\u001b[A\n",
      " 17%|█▋        | 71595/414113 [00:15<01:15, 4536.65it/s]\u001b[A\n",
      " 17%|█▋        | 72086/414113 [00:15<01:13, 4640.29it/s]\u001b[A\n",
      " 18%|█▊        | 72561/414113 [00:15<01:13, 4661.40it/s]\u001b[A\n",
      " 18%|█▊        | 73044/414113 [00:15<01:12, 4709.99it/s]\u001b[A\n",
      " 18%|█▊        | 73532/414113 [00:15<01:11, 4758.74it/s]\u001b[A\n",
      " 18%|█▊        | 74018/414113 [00:15<01:11, 4786.13it/s]\u001b[A\n",
      " 18%|█▊        | 74500/414113 [00:15<01:11, 4761.80it/s]\u001b[A\n",
      " 18%|█▊        | 74980/414113 [00:16<01:11, 4773.11it/s]\u001b[A\n",
      " 18%|█▊        | 75459/414113 [00:16<01:11, 4748.47it/s]\u001b[A\n",
      " 18%|█▊        | 75935/414113 [00:16<01:11, 4748.50it/s]\u001b[A\n",
      " 18%|█▊        | 76411/414113 [00:16<01:11, 4733.00it/s]\u001b[A\n",
      " 19%|█▊        | 76897/414113 [00:16<01:10, 4768.03it/s]\u001b[A\n",
      " 19%|█▊        | 77378/414113 [00:16<01:10, 4779.12it/s]\u001b[A\n",
      " 19%|█▉        | 77857/414113 [00:16<01:10, 4760.42it/s]\u001b[A\n",
      " 19%|█▉        | 78346/414113 [00:16<01:09, 4797.66it/s]\u001b[A\n",
      " 19%|█▉        | 78826/414113 [00:16<01:10, 4759.71it/s]\u001b[A\n",
      " 19%|█▉        | 79313/414113 [00:16<01:09, 4791.67it/s]\u001b[A\n",
      " 19%|█▉        | 79809/414113 [00:17<01:09, 4840.50it/s]\u001b[A\n",
      " 19%|█▉        | 80294/414113 [00:17<01:09, 4837.42it/s]\u001b[A\n",
      " 20%|█▉        | 80784/414113 [00:17<01:08, 4854.79it/s]\u001b[A\n",
      " 20%|█▉        | 81270/414113 [00:17<01:09, 4798.11it/s]\u001b[A\n",
      " 20%|█▉        | 81751/414113 [00:17<01:09, 4760.13it/s]\u001b[A\n",
      " 20%|█▉        | 82229/414113 [00:17<01:09, 4765.32it/s]\u001b[A\n",
      " 20%|█▉        | 82707/414113 [00:17<01:09, 4768.39it/s]\u001b[A\n",
      " 20%|██        | 83196/414113 [00:17<01:08, 4801.31it/s]\u001b[A\n",
      " 20%|██        | 83677/414113 [00:17<01:09, 4785.36it/s]\u001b[A\n",
      " 20%|██        | 84169/414113 [00:17<01:08, 4823.88it/s]\u001b[A\n",
      " 20%|██        | 84652/414113 [00:18<01:09, 4770.60it/s]\u001b[A\n",
      " 21%|██        | 85135/414113 [00:18<01:08, 4785.92it/s]\u001b[A\n",
      " 21%|██        | 85622/414113 [00:18<01:08, 4808.48it/s]\u001b[A\n",
      " 21%|██        | 86110/414113 [00:18<01:07, 4828.47it/s]\u001b[A\n",
      " 21%|██        | 86593/414113 [00:18<01:08, 4808.87it/s]\u001b[A\n",
      " 21%|██        | 87074/414113 [00:18<01:08, 4784.06it/s]\u001b[A\n",
      " 21%|██        | 87553/414113 [00:18<01:08, 4777.15it/s]\u001b[A\n",
      " 21%|██▏       | 88033/414113 [00:18<01:08, 4783.23it/s]\u001b[A\n",
      " 21%|██▏       | 88525/414113 [00:18<01:07, 4822.71it/s]\u001b[A\n",
      " 21%|██▏       | 89008/414113 [00:18<01:07, 4819.84it/s]\u001b[A\n",
      " 22%|██▏       | 89492/414113 [00:19<01:07, 4825.10it/s]\u001b[A\n",
      " 22%|██▏       | 89975/414113 [00:19<01:07, 4809.23it/s]\u001b[A\n",
      " 22%|██▏       | 90456/414113 [00:19<01:07, 4795.78it/s]\u001b[A\n",
      " 22%|██▏       | 90936/414113 [00:19<01:07, 4771.05it/s]\u001b[A\n",
      " 22%|██▏       | 91414/414113 [00:19<01:07, 4773.03it/s]\u001b[A\n",
      " 22%|██▏       | 91895/414113 [00:19<01:07, 4782.08it/s]\u001b[A\n",
      " 22%|██▏       | 92374/414113 [00:19<01:07, 4784.06it/s]\u001b[A\n",
      " 22%|██▏       | 92853/414113 [00:19<01:07, 4777.33it/s]\u001b[A\n",
      " 23%|██▎       | 93331/414113 [00:19<01:07, 4767.75it/s]\u001b[A\n",
      " 23%|██▎       | 93818/414113 [00:19<01:06, 4797.24it/s]\u001b[A\n",
      " 23%|██▎       | 94298/414113 [00:20<01:06, 4786.59it/s]\u001b[A\n",
      " 23%|██▎       | 94784/414113 [00:20<01:06, 4805.86it/s]\u001b[A\n",
      " 23%|██▎       | 95265/414113 [00:20<01:06, 4806.07it/s]\u001b[A\n",
      " 23%|██▎       | 95746/414113 [00:20<01:11, 4443.21it/s]\u001b[A\n",
      " 23%|██▎       | 96218/414113 [00:20<01:10, 4522.03it/s]\u001b[A\n",
      " 23%|██▎       | 96704/414113 [00:20<01:08, 4617.14it/s]\u001b[A\n",
      " 23%|██▎       | 97189/414113 [00:20<01:07, 4682.93it/s]\u001b[A\n",
      " 24%|██▎       | 97663/414113 [00:20<01:07, 4696.04it/s]\u001b[A\n",
      " 24%|██▎       | 98137/414113 [00:20<01:07, 4709.07it/s]\u001b[A\n",
      " 24%|██▍       | 98610/414113 [00:20<01:07, 4706.22it/s]\u001b[A\n",
      " 24%|██▍       | 99092/414113 [00:21<01:06, 4738.69it/s]\u001b[A\n",
      " 24%|██▍       | 99579/414113 [00:21<01:05, 4777.29it/s]\u001b[A\n",
      " 24%|██▍       | 100068/414113 [00:21<01:05, 4809.71it/s]\u001b[A\n",
      " 24%|██▍       | 100550/414113 [00:21<01:05, 4781.37it/s]\u001b[A\n",
      " 24%|██▍       | 101029/414113 [00:21<01:05, 4758.21it/s]\u001b[A\n",
      " 25%|██▍       | 101506/414113 [00:21<01:06, 4720.76it/s]\u001b[A\n",
      " 25%|██▍       | 101993/414113 [00:21<01:05, 4762.88it/s]\u001b[A\n",
      " 25%|██▍       | 102470/414113 [00:21<01:05, 4759.49it/s]\u001b[A\n",
      " 25%|██▍       | 102960/414113 [00:21<01:04, 4799.13it/s]\u001b[A\n",
      " 25%|██▍       | 103446/414113 [00:21<01:04, 4817.04it/s]\u001b[A\n",
      " 25%|██▌       | 103928/414113 [00:22<01:04, 4775.90it/s]\u001b[A\n",
      " 25%|██▌       | 104406/414113 [00:22<01:05, 4748.95it/s]\u001b[A\n",
      " 25%|██▌       | 104887/414113 [00:22<01:04, 4765.62it/s]\u001b[A\n",
      " 25%|██▌       | 105364/414113 [00:22<01:05, 4707.07it/s]\u001b[A\n",
      " 26%|██▌       | 105835/414113 [00:22<01:05, 4703.65it/s]\u001b[A\n",
      " 26%|██▌       | 106306/414113 [00:22<01:05, 4684.34it/s]\u001b[A\n",
      " 26%|██▌       | 106783/414113 [00:22<01:05, 4706.06it/s]\u001b[A\n",
      " 26%|██▌       | 107254/414113 [00:22<01:05, 4691.82it/s]\u001b[A\n",
      " 26%|██▌       | 107734/414113 [00:22<01:04, 4723.19it/s]\u001b[A\n",
      " 26%|██▌       | 108215/414113 [00:23<01:04, 4746.35it/s]\u001b[A\n",
      " 26%|██▌       | 108693/414113 [00:23<01:04, 4755.53it/s]\u001b[A\n",
      " 26%|██▋       | 109172/414113 [00:23<01:04, 4762.53it/s]\u001b[A\n",
      " 26%|██▋       | 109649/414113 [00:23<01:04, 4740.00it/s]\u001b[A\n",
      " 27%|██▋       | 110124/414113 [00:23<01:04, 4728.25it/s]\u001b[A\n",
      " 27%|██▋       | 110597/414113 [00:23<01:04, 4719.78it/s]\u001b[A\n",
      " 27%|██▋       | 111086/414113 [00:23<01:03, 4769.16it/s]\u001b[A\n",
      " 27%|██▋       | 111569/414113 [00:23<01:03, 4784.89it/s]\u001b[A\n",
      " 27%|██▋       | 112048/414113 [00:23<01:03, 4784.73it/s]\u001b[A\n",
      " 27%|██▋       | 112527/414113 [00:23<01:03, 4766.20it/s]\u001b[A\n",
      " 27%|██▋       | 113007/414113 [00:24<01:03, 4775.05it/s]\u001b[A\n",
      " 27%|██▋       | 113498/414113 [00:24<01:02, 4811.78it/s]\u001b[A\n",
      " 28%|██▊       | 113981/414113 [00:24<01:02, 4815.55it/s]\u001b[A\n",
      " 28%|██▊       | 114463/414113 [00:24<01:11, 4174.42it/s]\u001b[A\n",
      " 28%|██▊       | 114946/414113 [00:24<01:08, 4351.13it/s]\u001b[A\n",
      " 28%|██▊       | 115429/414113 [00:24<01:06, 4482.95it/s]\u001b[A\n",
      " 28%|██▊       | 115916/414113 [00:24<01:04, 4591.32it/s]\u001b[A\n",
      " 28%|██▊       | 116402/414113 [00:24<01:03, 4667.53it/s]\u001b[A\n",
      " 28%|██▊       | 116892/414113 [00:24<01:02, 4734.56it/s]\u001b[A\n",
      " 28%|██▊       | 117378/414113 [00:24<01:02, 4770.21it/s]\u001b[A\n",
      " 28%|██▊       | 117868/414113 [00:25<01:01, 4805.70it/s]\u001b[A\n",
      " 29%|██▊       | 118351/414113 [00:25<01:02, 4769.55it/s]\u001b[A\n",
      " 29%|██▊       | 118837/414113 [00:25<01:01, 4795.91it/s]\u001b[A\n",
      " 29%|██▉       | 119330/414113 [00:25<01:00, 4833.93it/s]\u001b[A\n",
      " 29%|██▉       | 119816/414113 [00:25<01:00, 4840.99it/s]\u001b[A\n",
      " 29%|██▉       | 120301/414113 [00:25<01:01, 4811.31it/s]\u001b[A\n",
      " 29%|██▉       | 120785/414113 [00:25<01:00, 4818.39it/s]\u001b[A\n",
      " 29%|██▉       | 121273/414113 [00:25<01:00, 4835.11it/s]\u001b[A\n",
      " 29%|██▉       | 121757/414113 [00:25<01:00, 4810.96it/s]\u001b[A\n",
      " 30%|██▉       | 122239/414113 [00:25<01:03, 4623.00it/s]\u001b[A\n",
      " 30%|██▉       | 122712/414113 [00:26<01:02, 4654.47it/s]\u001b[A\n",
      " 30%|██▉       | 123189/414113 [00:26<01:02, 4686.78it/s]\u001b[A\n",
      " 30%|██▉       | 123666/414113 [00:26<01:01, 4710.18it/s]\u001b[A\n",
      " 30%|██▉       | 124154/414113 [00:26<01:00, 4758.97it/s]\u001b[A\n",
      " 30%|███       | 124631/414113 [00:26<01:00, 4756.54it/s]\u001b[A\n",
      " 30%|███       | 125108/414113 [00:26<01:02, 4623.29it/s]\u001b[A\n",
      " 30%|███       | 125586/414113 [00:26<01:01, 4667.28it/s]\u001b[A\n",
      " 30%|███       | 126066/414113 [00:26<01:01, 4704.30it/s]\u001b[A\n",
      " 31%|███       | 126551/414113 [00:26<01:00, 4746.06it/s]\u001b[A\n",
      " 31%|███       | 127055/414113 [00:26<00:59, 4830.35it/s]\u001b[A\n",
      " 31%|███       | 127550/414113 [00:27<00:58, 4863.66it/s]\u001b[A\n",
      " 31%|███       | 128037/414113 [00:27<00:58, 4862.51it/s]\u001b[A\n",
      " 31%|███       | 128530/414113 [00:27<00:58, 4880.28it/s]\u001b[A\n",
      " 31%|███       | 129020/414113 [00:27<00:58, 4885.37it/s]\u001b[A\n",
      " 31%|███▏      | 129509/414113 [00:27<00:58, 4885.16it/s]\u001b[A\n",
      " 31%|███▏      | 130005/414113 [00:27<00:57, 4905.41it/s]\u001b[A\n",
      " 32%|███▏      | 130496/414113 [00:27<00:58, 4881.33it/s]\u001b[A\n",
      " 32%|███▏      | 130985/414113 [00:27<00:58, 4852.09it/s]\u001b[A\n",
      " 32%|███▏      | 131489/414113 [00:27<00:57, 4905.91it/s]\u001b[A\n",
      " 32%|███▏      | 131980/414113 [00:28<00:57, 4899.71it/s]\u001b[A\n",
      " 32%|███▏      | 132471/414113 [00:28<00:57, 4886.01it/s]\u001b[A\n",
      " 32%|███▏      | 132961/414113 [00:28<00:57, 4888.86it/s]\u001b[A\n",
      " 32%|███▏      | 133450/414113 [00:28<00:57, 4872.65it/s]\u001b[A\n",
      " 32%|███▏      | 133938/414113 [00:28<00:58, 4798.41it/s]\u001b[A\n",
      " 32%|███▏      | 134419/414113 [00:28<00:58, 4789.56it/s]\u001b[A\n",
      " 33%|███▎      | 134899/414113 [00:28<00:59, 4654.00it/s]\u001b[A\n",
      " 33%|███▎      | 135390/414113 [00:28<00:58, 4725.75it/s]\u001b[A\n",
      " 33%|███▎      | 135864/414113 [00:28<00:58, 4722.88it/s]\u001b[A\n",
      " 33%|███▎      | 136363/414113 [00:28<00:57, 4799.36it/s]\u001b[A\n",
      " 33%|███▎      | 136844/414113 [00:29<00:58, 4780.37it/s]\u001b[A\n",
      " 33%|███▎      | 137329/414113 [00:29<00:57, 4799.88it/s]\u001b[A\n",
      " 33%|███▎      | 137810/414113 [00:29<00:57, 4797.73it/s]\u001b[A\n",
      " 33%|███▎      | 138293/414113 [00:29<00:57, 4805.91it/s]\u001b[A\n",
      " 34%|███▎      | 138774/414113 [00:29<00:57, 4781.67it/s]\u001b[A\n",
      " 34%|███▎      | 139262/414113 [00:29<00:57, 4810.58it/s]\u001b[A\n",
      " 34%|███▎      | 139744/414113 [00:29<00:57, 4807.30it/s]\u001b[A\n",
      " 34%|███▍      | 140225/414113 [00:29<00:57, 4781.58it/s]\u001b[A\n",
      " 34%|███▍      | 140704/414113 [00:29<00:58, 4707.24it/s]\u001b[A\n",
      " 34%|███▍      | 141184/414113 [00:29<00:57, 4733.97it/s]\u001b[A\n",
      " 34%|███▍      | 141658/414113 [00:30<00:57, 4735.06it/s]\u001b[A\n",
      " 34%|███▍      | 142156/414113 [00:30<00:56, 4802.90it/s]\u001b[A\n",
      " 34%|███▍      | 142648/414113 [00:30<00:56, 4836.37it/s]\u001b[A\n",
      " 35%|███▍      | 143132/414113 [00:30<00:56, 4821.38it/s]\u001b[A\n",
      " 35%|███▍      | 143619/414113 [00:30<00:55, 4835.64it/s]\u001b[A\n",
      " 35%|███▍      | 144103/414113 [00:30<00:56, 4795.14it/s]\u001b[A\n",
      " 35%|███▍      | 144586/414113 [00:30<00:56, 4803.90it/s]\u001b[A\n",
      " 35%|███▌      | 145069/414113 [00:30<00:55, 4809.48it/s]\u001b[A\n",
      " 35%|███▌      | 145551/414113 [00:30<00:55, 4806.99it/s]\u001b[A\n",
      " 35%|███▌      | 146047/414113 [00:30<00:55, 4849.78it/s]\u001b[A\n",
      " 35%|███▌      | 146533/414113 [00:31<00:55, 4852.00it/s]\u001b[A\n",
      " 36%|███▌      | 147021/414113 [00:31<00:54, 4859.37it/s]\u001b[A\n",
      " 36%|███▌      | 147508/414113 [00:31<00:55, 4825.56it/s]\u001b[A\n",
      " 36%|███▌      | 147991/414113 [00:31<00:55, 4805.14it/s]\u001b[A\n",
      " 36%|███▌      | 148481/414113 [00:31<00:54, 4831.08it/s]\u001b[A\n",
      " 36%|███▌      | 148965/414113 [00:31<00:55, 4815.26it/s]\u001b[A\n",
      " 36%|███▌      | 149451/414113 [00:31<00:54, 4826.41it/s]\u001b[A\n",
      " 36%|███▌      | 149934/414113 [00:31<00:54, 4826.60it/s]\u001b[A\n",
      " 36%|███▋      | 150418/414113 [00:31<00:54, 4829.54it/s]\u001b[A\n",
      " 36%|███▋      | 150911/414113 [00:31<00:54, 4858.03it/s]\u001b[A\n",
      " 37%|███▋      | 151399/414113 [00:32<00:54, 4863.42it/s]\u001b[A\n",
      " 37%|███▋      | 151887/414113 [00:32<00:53, 4867.07it/s]\u001b[A\n",
      " 37%|███▋      | 152382/414113 [00:32<00:53, 4889.85it/s]\u001b[A\n",
      " 37%|███▋      | 152872/414113 [00:32<00:53, 4855.27it/s]\u001b[A\n",
      " 37%|███▋      | 153362/414113 [00:32<00:53, 4865.99it/s]\u001b[A\n",
      " 37%|███▋      | 153854/414113 [00:32<00:53, 4882.06it/s]\u001b[A\n",
      " 37%|███▋      | 154349/414113 [00:32<00:52, 4902.12it/s]\u001b[A\n",
      " 37%|███▋      | 154840/414113 [00:32<00:53, 4884.27it/s]\u001b[A\n",
      " 38%|███▊      | 155329/414113 [00:32<00:53, 4858.42it/s]\u001b[A\n",
      " 38%|███▊      | 155817/414113 [00:32<00:53, 4861.97it/s]\u001b[A\n",
      " 38%|███▊      | 156308/414113 [00:33<00:52, 4874.28it/s]\u001b[A\n",
      " 38%|███▊      | 156796/414113 [00:33<00:52, 4864.53it/s]\u001b[A\n",
      " 38%|███▊      | 157295/414113 [00:33<00:52, 4900.04it/s]\u001b[A\n",
      " 38%|███▊      | 157786/414113 [00:33<00:52, 4850.15it/s]\u001b[A\n",
      " 38%|███▊      | 158275/414113 [00:33<00:52, 4859.83it/s]\u001b[A\n",
      " 38%|███▊      | 158762/414113 [00:33<00:53, 4816.32it/s]\u001b[A\n",
      " 38%|███▊      | 159245/414113 [00:33<00:52, 4817.53it/s]\u001b[A\n",
      " 39%|███▊      | 159730/414113 [00:33<00:52, 4824.73it/s]\u001b[A\n",
      " 39%|███▊      | 160220/414113 [00:33<00:52, 4845.95it/s]\u001b[A\n",
      " 39%|███▉      | 160705/414113 [00:33<00:53, 4765.77it/s]\u001b[A\n",
      " 39%|███▉      | 161200/414113 [00:34<00:52, 4817.72it/s]\u001b[A\n",
      " 39%|███▉      | 161696/414113 [00:34<00:51, 4857.81it/s]\u001b[A\n",
      " 39%|███▉      | 162183/414113 [00:34<00:51, 4850.32it/s]\u001b[A\n",
      " 39%|███▉      | 162669/414113 [00:34<00:51, 4848.09it/s]\u001b[A\n",
      " 39%|███▉      | 163154/414113 [00:34<00:52, 4805.44it/s]\u001b[A\n",
      " 40%|███▉      | 163635/414113 [00:34<00:52, 4803.56it/s]\u001b[A\n",
      " 40%|███▉      | 164116/414113 [00:34<00:52, 4774.43it/s]\u001b[A\n",
      " 40%|███▉      | 164594/414113 [00:34<00:52, 4773.54it/s]\u001b[A\n",
      " 40%|███▉      | 165072/414113 [00:34<00:54, 4592.93it/s]\u001b[A\n",
      " 40%|███▉      | 165551/414113 [00:34<00:53, 4650.19it/s]\u001b[A\n",
      " 40%|████      | 166018/414113 [00:35<00:53, 4633.94it/s]\u001b[A\n",
      " 40%|████      | 166484/414113 [00:35<00:53, 4640.20it/s]\u001b[A\n",
      " 40%|████      | 166949/414113 [00:35<00:53, 4605.53it/s]\u001b[A\n",
      " 40%|████      | 167422/414113 [00:35<00:53, 4640.84it/s]\u001b[A\n",
      " 41%|████      | 167887/414113 [00:35<00:53, 4640.83it/s]\u001b[A\n",
      " 41%|████      | 168370/414113 [00:35<00:52, 4693.38it/s]\u001b[A\n",
      " 41%|████      | 168840/414113 [00:35<01:25, 2861.69it/s]\u001b[A\n",
      " 41%|████      | 169298/414113 [00:36<01:15, 3224.16it/s]\u001b[A\n",
      " 41%|████      | 169772/414113 [00:36<01:08, 3565.42it/s]\u001b[A\n",
      " 41%|████      | 170234/414113 [00:36<01:03, 3827.24it/s]\u001b[A\n",
      " 41%|████      | 170714/414113 [00:36<00:59, 4073.57it/s]\u001b[A\n",
      " 41%|████▏     | 171189/414113 [00:36<00:57, 4253.12it/s]\u001b[A\n",
      " 41%|████▏     | 171653/414113 [00:36<00:55, 4360.69it/s]\u001b[A\n",
      " 42%|████▏     | 172144/414113 [00:36<00:53, 4512.00it/s]\u001b[A\n",
      " 42%|████▏     | 172631/414113 [00:36<00:52, 4613.49it/s]\u001b[A\n",
      " 42%|████▏     | 173115/414113 [00:36<00:51, 4676.63it/s]\u001b[A\n",
      " 42%|████▏     | 173602/414113 [00:36<00:50, 4731.61it/s]\u001b[A\n",
      " 42%|████▏     | 174082/414113 [00:37<00:50, 4722.45it/s]\u001b[A\n",
      " 42%|████▏     | 174564/414113 [00:37<00:50, 4749.34it/s]\u001b[A\n",
      " 42%|████▏     | 175043/414113 [00:37<00:50, 4708.50it/s]\u001b[A\n",
      " 42%|████▏     | 175517/414113 [00:37<00:50, 4684.84it/s]\u001b[A\n",
      " 42%|████▏     | 175998/414113 [00:37<00:50, 4721.33it/s]\u001b[A\n",
      " 43%|████▎     | 176472/414113 [00:37<00:50, 4722.83it/s]\u001b[A\n",
      " 43%|████▎     | 176958/414113 [00:37<00:49, 4761.39it/s]\u001b[A\n",
      " 43%|████▎     | 177446/414113 [00:37<00:49, 4794.96it/s]\u001b[A\n",
      " 43%|████▎     | 177935/414113 [00:37<00:48, 4822.68it/s]\u001b[A\n",
      " 43%|████▎     | 178418/414113 [00:37<00:48, 4823.52it/s]\u001b[A\n",
      " 43%|████▎     | 178907/414113 [00:38<00:48, 4841.61it/s]\u001b[A\n",
      " 43%|████▎     | 179392/414113 [00:38<00:48, 4808.85it/s]\u001b[A\n",
      " 43%|████▎     | 179878/414113 [00:38<00:48, 4820.82it/s]\u001b[A\n",
      " 44%|████▎     | 180361/414113 [00:38<00:48, 4774.26it/s]\u001b[A\n",
      " 44%|████▎     | 180839/414113 [00:38<00:49, 4742.77it/s]\u001b[A\n",
      " 44%|████▍     | 181321/414113 [00:38<00:48, 4762.92it/s]\u001b[A\n",
      " 44%|████▍     | 181806/414113 [00:38<00:48, 4788.01it/s]\u001b[A\n",
      " 44%|████▍     | 182285/414113 [00:38<00:48, 4767.37it/s]\u001b[A\n",
      " 44%|████▍     | 182762/414113 [00:38<00:48, 4764.66it/s]\u001b[A\n",
      " 44%|████▍     | 183239/414113 [00:38<00:48, 4761.98it/s]\u001b[A\n",
      " 44%|████▍     | 183716/414113 [00:39<00:48, 4743.42it/s]\u001b[A\n",
      " 44%|████▍     | 184191/414113 [00:39<00:48, 4743.69it/s]\u001b[A\n",
      " 45%|████▍     | 184682/414113 [00:39<00:47, 4791.25it/s]\u001b[A\n",
      " 45%|████▍     | 185162/414113 [00:39<00:47, 4792.84it/s]\u001b[A\n",
      " 45%|████▍     | 185642/414113 [00:39<00:47, 4779.71it/s]\u001b[A\n",
      " 45%|████▍     | 186121/414113 [00:39<00:47, 4762.04it/s]\u001b[A\n",
      " 45%|████▌     | 186617/414113 [00:39<00:47, 4817.60it/s]\u001b[A\n",
      " 45%|████▌     | 187103/414113 [00:39<00:47, 4828.48it/s]\u001b[A\n",
      " 45%|████▌     | 187586/414113 [00:39<00:46, 4826.33it/s]\u001b[A\n",
      " 45%|████▌     | 188071/414113 [00:39<00:46, 4832.17it/s]\u001b[A\n",
      " 46%|████▌     | 188555/414113 [00:40<00:46, 4803.15it/s]\u001b[A\n",
      " 46%|████▌     | 189036/414113 [00:40<00:47, 4787.34it/s]\u001b[A\n",
      " 46%|████▌     | 189523/414113 [00:40<00:46, 4811.07it/s]\u001b[A\n",
      " 46%|████▌     | 190006/414113 [00:40<00:46, 4815.15it/s]\u001b[A\n",
      " 46%|████▌     | 190490/414113 [00:40<00:46, 4822.41it/s]\u001b[A\n",
      " 46%|████▌     | 190973/414113 [00:40<00:46, 4814.78it/s]\u001b[A\n",
      " 46%|████▌     | 191455/414113 [00:40<00:46, 4788.82it/s]\u001b[A\n",
      " 46%|████▋     | 191934/414113 [00:40<00:46, 4782.76it/s]\u001b[A\n",
      " 46%|████▋     | 192414/414113 [00:40<00:46, 4786.84it/s]\u001b[A\n",
      " 47%|████▋     | 192893/414113 [00:40<00:46, 4754.64it/s]\u001b[A\n",
      " 47%|████▋     | 193372/414113 [00:41<00:46, 4762.67it/s]\u001b[A\n",
      " 47%|████▋     | 193849/414113 [00:41<00:46, 4749.58it/s]\u001b[A\n",
      " 47%|████▋     | 194325/414113 [00:41<00:46, 4713.59it/s]\u001b[A\n",
      " 47%|████▋     | 194797/414113 [00:41<00:46, 4713.18it/s]\u001b[A\n",
      " 47%|████▋     | 195276/414113 [00:41<00:46, 4734.57it/s]\u001b[A\n",
      " 47%|████▋     | 195753/414113 [00:41<00:46, 4743.56it/s]\u001b[A\n",
      " 47%|████▋     | 196228/414113 [00:41<00:46, 4721.65it/s]\u001b[A\n",
      " 47%|████▋     | 196703/414113 [00:41<00:45, 4727.82it/s]\u001b[A\n",
      " 48%|████▊     | 197183/414113 [00:41<00:45, 4747.15it/s]\u001b[A\n",
      " 48%|████▊     | 197681/414113 [00:41<00:44, 4813.97it/s]\u001b[A\n",
      " 48%|████▊     | 198171/414113 [00:42<00:44, 4837.96it/s]\u001b[A\n",
      " 48%|████▊     | 198656/414113 [00:42<00:44, 4832.23it/s]\u001b[A\n",
      " 48%|████▊     | 199148/414113 [00:42<00:44, 4857.22it/s]\u001b[A\n",
      " 48%|████▊     | 199634/414113 [00:42<00:44, 4798.82it/s]\u001b[A\n",
      " 48%|████▊     | 200115/414113 [00:42<00:44, 4778.38it/s]\u001b[A\n",
      " 48%|████▊     | 200608/414113 [00:42<00:44, 4821.84it/s]\u001b[A\n",
      " 49%|████▊     | 201098/414113 [00:42<00:43, 4844.55it/s]\u001b[A\n",
      " 49%|████▊     | 201583/414113 [00:42<00:43, 4842.40it/s]\u001b[A\n",
      " 49%|████▉     | 202068/414113 [00:42<00:44, 4817.39it/s]\u001b[A\n",
      " 49%|████▉     | 202560/414113 [00:42<00:43, 4847.20it/s]\u001b[A\n",
      " 49%|████▉     | 203045/414113 [00:43<00:44, 4792.13it/s]\u001b[A\n",
      " 49%|████▉     | 203526/414113 [00:43<00:43, 4796.89it/s]\u001b[A\n",
      " 49%|████▉     | 204007/414113 [00:43<00:43, 4799.68it/s]\u001b[A\n",
      " 49%|████▉     | 204489/414113 [00:43<00:43, 4805.04it/s]\u001b[A\n",
      " 49%|████▉     | 204976/414113 [00:43<00:43, 4823.48it/s]\u001b[A\n",
      " 50%|████▉     | 205459/414113 [00:43<00:43, 4816.98it/s]\u001b[A\n",
      " 50%|████▉     | 205952/414113 [00:43<00:42, 4849.12it/s]\u001b[A\n",
      " 50%|████▉     | 206438/414113 [00:43<00:43, 4813.72it/s]\u001b[A\n",
      " 50%|████▉     | 206923/414113 [00:43<00:42, 4823.38it/s]\u001b[A\n",
      " 50%|█████     | 207406/414113 [00:43<00:42, 4814.52it/s]\u001b[A\n",
      " 50%|█████     | 207888/414113 [00:44<00:42, 4812.28it/s]\u001b[A\n",
      " 50%|█████     | 208383/414113 [00:44<00:42, 4852.31it/s]\u001b[A\n",
      " 50%|█████     | 208869/414113 [00:44<00:42, 4848.54it/s]\u001b[A\n",
      " 51%|█████     | 209365/414113 [00:44<00:41, 4878.70it/s]\u001b[A\n",
      " 51%|█████     | 209853/414113 [00:44<00:42, 4846.71it/s]\u001b[A\n",
      " 51%|█████     | 210338/414113 [00:44<00:42, 4836.49it/s]\u001b[A\n",
      " 51%|█████     | 210832/414113 [00:44<00:41, 4864.70it/s]\u001b[A\n",
      " 51%|█████     | 211319/414113 [00:44<00:41, 4848.59it/s]\u001b[A\n",
      " 51%|█████     | 211806/414113 [00:44<00:41, 4854.51it/s]\u001b[A\n",
      " 51%|█████▏    | 212300/414113 [00:44<00:41, 4876.29it/s]\u001b[A\n",
      " 51%|█████▏    | 212788/414113 [00:45<00:41, 4848.28it/s]\u001b[A\n",
      " 52%|█████▏    | 213273/414113 [00:45<00:41, 4839.33it/s]\u001b[A\n",
      " 52%|█████▏    | 213757/414113 [00:45<00:41, 4820.41it/s]\u001b[A\n",
      " 52%|█████▏    | 214242/414113 [00:45<00:41, 4828.93it/s]\u001b[A\n",
      " 52%|█████▏    | 214725/414113 [00:45<00:41, 4802.15it/s]\u001b[A\n",
      " 52%|█████▏    | 215209/414113 [00:45<00:41, 4812.68it/s]\u001b[A\n",
      " 52%|█████▏    | 215692/414113 [00:45<00:41, 4817.01it/s]\u001b[A\n",
      " 52%|█████▏    | 216177/414113 [00:45<00:41, 4824.35it/s]\u001b[A\n",
      " 52%|█████▏    | 216660/414113 [00:45<00:41, 4797.35it/s]\u001b[A\n",
      " 52%|█████▏    | 217140/414113 [00:45<00:42, 4601.07it/s]\u001b[A\n",
      " 53%|█████▎    | 217627/414113 [00:46<00:42, 4677.51it/s]\u001b[A\n",
      " 53%|█████▎    | 218111/414113 [00:46<00:41, 4722.67it/s]\u001b[A\n",
      " 53%|█████▎    | 218596/414113 [00:46<00:41, 4759.76it/s]\u001b[A\n",
      " 53%|█████▎    | 219089/414113 [00:46<00:40, 4807.69it/s]\u001b[A\n",
      " 53%|█████▎    | 219572/414113 [00:46<00:40, 4811.98it/s]\u001b[A\n",
      " 53%|█████▎    | 220054/414113 [00:46<00:40, 4810.68it/s]\u001b[A\n",
      " 53%|█████▎    | 220537/414113 [00:46<00:40, 4815.04it/s]\u001b[A\n",
      " 53%|█████▎    | 221019/414113 [00:46<00:40, 4792.51it/s]\u001b[A\n",
      " 53%|█████▎    | 221502/414113 [00:46<00:40, 4801.15it/s]\u001b[A\n",
      " 54%|█████▎    | 221994/414113 [00:46<00:39, 4835.47it/s]\u001b[A\n",
      " 54%|█████▎    | 222484/414113 [00:47<00:39, 4853.70it/s]\u001b[A\n",
      " 54%|█████▍    | 222970/414113 [00:47<00:39, 4851.32it/s]\u001b[A\n",
      " 54%|█████▍    | 223456/414113 [00:47<00:39, 4853.90it/s]\u001b[A\n",
      " 54%|█████▍    | 223942/414113 [00:47<00:39, 4838.87it/s]\u001b[A\n",
      " 54%|█████▍    | 224426/414113 [00:47<00:39, 4812.55it/s]\u001b[A\n",
      " 54%|█████▍    | 224927/414113 [00:47<00:38, 4869.81it/s]\u001b[A\n",
      " 54%|█████▍    | 225421/414113 [00:47<00:38, 4887.63it/s]\u001b[A\n",
      " 55%|█████▍    | 225910/414113 [00:47<00:38, 4863.54it/s]\u001b[A\n",
      " 55%|█████▍    | 226419/414113 [00:47<00:38, 4927.59it/s]\u001b[A\n",
      " 55%|█████▍    | 226913/414113 [00:48<00:38, 4907.50it/s]\u001b[A\n",
      " 55%|█████▍    | 227404/414113 [00:48<00:38, 4895.70it/s]\u001b[A\n",
      " 55%|█████▌    | 227894/414113 [00:48<00:38, 4881.09it/s]\u001b[A\n",
      " 55%|█████▌    | 228383/414113 [00:48<00:38, 4882.33it/s]\u001b[A\n",
      " 55%|█████▌    | 228874/414113 [00:48<00:37, 4888.00it/s]\u001b[A\n",
      " 55%|█████▌    | 229363/414113 [00:48<00:38, 4835.83it/s]\u001b[A\n",
      " 56%|█████▌    | 229848/414113 [00:48<00:38, 4839.43it/s]\u001b[A\n",
      " 56%|█████▌    | 230333/414113 [00:48<00:38, 4831.22it/s]\u001b[A\n",
      " 56%|█████▌    | 230817/414113 [00:48<00:37, 4825.61it/s]\u001b[A\n",
      " 56%|█████▌    | 231300/414113 [00:48<00:38, 4810.29it/s]\u001b[A\n",
      " 56%|█████▌    | 231782/414113 [00:49<00:37, 4800.30it/s]\u001b[A\n",
      " 56%|█████▌    | 232263/414113 [00:49<00:38, 4762.36it/s]\u001b[A\n",
      " 56%|█████▌    | 232740/414113 [00:49<00:38, 4738.80it/s]\u001b[A\n",
      " 56%|█████▋    | 233228/414113 [00:49<00:37, 4779.68it/s]\u001b[A\n",
      " 56%|█████▋    | 233714/414113 [00:49<00:37, 4803.22it/s]\u001b[A\n",
      " 57%|█████▋    | 234196/414113 [00:49<00:37, 4808.03it/s]\u001b[A\n",
      " 57%|█████▋    | 234677/414113 [00:49<00:37, 4805.55it/s]\u001b[A\n",
      " 57%|█████▋    | 235158/414113 [00:49<00:37, 4790.18it/s]\u001b[A\n",
      " 57%|█████▋    | 235638/414113 [00:49<00:37, 4790.64it/s]\u001b[A\n",
      " 57%|█████▋    | 236136/414113 [00:49<00:36, 4843.20it/s]\u001b[A\n",
      " 57%|█████▋    | 236621/414113 [00:50<00:36, 4835.28it/s]\u001b[A\n",
      " 57%|█████▋    | 237105/414113 [00:50<00:36, 4822.68it/s]\u001b[A\n",
      " 57%|█████▋    | 237591/414113 [00:50<00:36, 4831.88it/s]\u001b[A\n",
      " 57%|█████▋    | 238075/414113 [00:50<00:36, 4825.74it/s]\u001b[A\n",
      " 58%|█████▊    | 238558/414113 [00:50<00:36, 4810.62it/s]\u001b[A\n",
      " 58%|█████▊    | 239040/414113 [00:50<00:36, 4770.11it/s]\u001b[A\n",
      " 58%|█████▊    | 239518/414113 [00:50<00:36, 4742.53it/s]\u001b[A\n",
      " 58%|█████▊    | 239993/414113 [00:50<00:36, 4732.94it/s]\u001b[A\n",
      " 58%|█████▊    | 240467/414113 [00:50<00:36, 4711.72it/s]\u001b[A\n",
      " 58%|█████▊    | 240957/414113 [00:50<00:36, 4765.49it/s]\u001b[A\n",
      " 58%|█████▊    | 241434/414113 [00:51<00:36, 4766.18it/s]\u001b[A\n",
      " 58%|█████▊    | 241912/414113 [00:51<00:36, 4768.51it/s]\u001b[A\n",
      " 59%|█████▊    | 242389/414113 [00:51<00:36, 4754.90it/s]\u001b[A\n",
      " 59%|█████▊    | 242870/414113 [00:51<00:35, 4768.60it/s]\u001b[A\n",
      " 59%|█████▉    | 243349/414113 [00:51<00:35, 4772.93it/s]\u001b[A\n",
      " 59%|█████▉    | 243827/414113 [00:51<00:35, 4746.28it/s]\u001b[A\n",
      " 59%|█████▉    | 244302/414113 [00:51<00:35, 4741.70it/s]\u001b[A\n",
      " 59%|█████▉    | 244785/414113 [00:51<00:35, 4767.85it/s]\u001b[A\n",
      " 59%|█████▉    | 245262/414113 [00:51<00:35, 4760.85it/s]\u001b[A\n",
      " 59%|█████▉    | 245741/414113 [00:51<00:35, 4768.42it/s]\u001b[A\n",
      " 59%|█████▉    | 246227/414113 [00:52<00:35, 4792.88it/s]\u001b[A\n",
      " 60%|█████▉    | 246707/414113 [00:52<00:34, 4791.90it/s]\u001b[A\n",
      " 60%|█████▉    | 247187/414113 [00:52<00:34, 4773.32it/s]\u001b[A\n",
      " 60%|█████▉    | 247666/414113 [00:52<00:34, 4775.94it/s]\u001b[A\n",
      " 60%|█████▉    | 248144/414113 [00:52<00:34, 4764.64it/s]\u001b[A\n",
      " 60%|██████    | 248621/414113 [00:52<00:34, 4753.58it/s]\u001b[A\n",
      " 60%|██████    | 249104/414113 [00:52<00:34, 4773.71it/s]\u001b[A\n",
      " 60%|██████    | 249584/414113 [00:52<00:34, 4781.40it/s]\u001b[A\n",
      " 60%|██████    | 250065/414113 [00:52<00:34, 4788.94it/s]\u001b[A\n",
      " 61%|██████    | 250554/414113 [00:52<00:33, 4817.48it/s]\u001b[A\n",
      " 61%|██████    | 251036/414113 [00:53<00:34, 4769.54it/s]\u001b[A\n",
      " 61%|██████    | 251527/414113 [00:53<00:33, 4809.21it/s]\u001b[A\n",
      " 61%|██████    | 252009/414113 [00:53<00:33, 4795.19it/s]\u001b[A\n",
      " 61%|██████    | 252493/414113 [00:53<00:33, 4808.02it/s]\u001b[A\n",
      " 61%|██████    | 252974/414113 [00:53<00:33, 4794.07it/s]\u001b[A\n",
      " 61%|██████    | 253454/414113 [00:53<00:33, 4792.21it/s]\u001b[A\n",
      " 61%|██████▏   | 253934/414113 [00:53<00:33, 4780.69it/s]\u001b[A\n",
      " 61%|██████▏   | 254413/414113 [00:53<00:33, 4766.10it/s]\u001b[A\n",
      " 62%|██████▏   | 254894/414113 [00:53<00:33, 4779.13it/s]\u001b[A\n",
      " 62%|██████▏   | 255378/414113 [00:53<00:33, 4795.80it/s]\u001b[A\n",
      " 62%|██████▏   | 255858/414113 [00:54<00:33, 4761.08it/s]\u001b[A\n",
      " 62%|██████▏   | 256342/414113 [00:54<00:32, 4783.41it/s]\u001b[A\n",
      " 62%|██████▏   | 256821/414113 [00:54<00:32, 4769.98it/s]\u001b[A\n",
      " 62%|██████▏   | 257299/414113 [00:54<00:33, 4748.82it/s]\u001b[A\n",
      " 62%|██████▏   | 257785/414113 [00:54<00:32, 4778.52it/s]\u001b[A\n",
      " 62%|██████▏   | 258268/414113 [00:54<00:32, 4793.19it/s]\u001b[A\n",
      " 62%|██████▏   | 258748/414113 [00:54<00:32, 4783.14it/s]\u001b[A\n",
      " 63%|██████▎   | 259236/414113 [00:54<00:32, 4810.50it/s]\u001b[A\n",
      " 63%|██████▎   | 259718/414113 [00:54<00:32, 4792.23it/s]\u001b[A\n",
      " 63%|██████▎   | 260198/414113 [00:54<00:32, 4753.01it/s]\u001b[A\n",
      " 63%|██████▎   | 260676/414113 [00:55<00:32, 4759.47it/s]\u001b[A\n",
      " 63%|██████▎   | 261161/414113 [00:55<00:31, 4785.28it/s]\u001b[A\n",
      " 63%|██████▎   | 261643/414113 [00:55<00:31, 4794.48it/s]\u001b[A\n",
      " 63%|██████▎   | 262124/414113 [00:55<00:31, 4798.67it/s]\u001b[A\n",
      " 63%|██████▎   | 262604/414113 [00:55<00:31, 4798.33it/s]\u001b[A\n",
      " 64%|██████▎   | 263084/414113 [00:55<00:31, 4777.06it/s]\u001b[A\n",
      " 64%|██████▎   | 263564/414113 [00:55<00:31, 4783.47it/s]\u001b[A\n",
      " 64%|██████▍   | 264043/414113 [00:55<00:31, 4754.53it/s]\u001b[A\n",
      " 64%|██████▍   | 264522/414113 [00:55<00:31, 4764.78it/s]\u001b[A\n",
      " 64%|██████▍   | 264999/414113 [00:55<00:31, 4747.54it/s]\u001b[A\n",
      " 64%|██████▍   | 265474/414113 [00:56<00:31, 4730.95it/s]\u001b[A\n",
      " 64%|██████▍   | 265948/414113 [00:56<00:31, 4724.10it/s]\u001b[A\n",
      " 64%|██████▍   | 266424/414113 [00:56<00:31, 4733.40it/s]\u001b[A\n",
      " 64%|██████▍   | 266913/414113 [00:56<00:30, 4779.12it/s]\u001b[A\n",
      " 65%|██████▍   | 267392/414113 [00:56<00:30, 4776.75it/s]\u001b[A\n",
      " 65%|██████▍   | 267874/414113 [00:56<00:30, 4786.71it/s]\u001b[A\n",
      " 65%|██████▍   | 268355/414113 [00:56<00:30, 4792.94it/s]\u001b[A\n",
      " 65%|██████▍   | 268835/414113 [00:56<00:30, 4788.28it/s]\u001b[A\n",
      " 65%|██████▌   | 269322/414113 [00:56<00:30, 4811.43it/s]\u001b[A\n",
      " 65%|██████▌   | 269807/414113 [00:56<00:29, 4822.01it/s]\u001b[A\n",
      " 65%|██████▌   | 270291/414113 [00:57<00:29, 4826.96it/s]\u001b[A\n",
      " 65%|██████▌   | 270777/414113 [00:57<00:29, 4834.77it/s]\u001b[A\n",
      " 66%|██████▌   | 271261/414113 [00:57<00:29, 4832.38it/s]\u001b[A\n",
      " 66%|██████▌   | 271747/414113 [00:57<00:29, 4840.40it/s]\u001b[A\n",
      " 66%|██████▌   | 272232/414113 [00:57<00:29, 4810.21it/s]\u001b[A\n",
      " 66%|██████▌   | 272714/414113 [00:57<00:29, 4784.35it/s]\u001b[A\n",
      " 66%|██████▌   | 273201/414113 [00:57<00:29, 4809.23it/s]\u001b[A\n",
      " 66%|██████▌   | 273683/414113 [00:57<00:29, 4810.73it/s]\u001b[A\n",
      " 66%|██████▌   | 274165/414113 [00:57<00:29, 4765.24it/s]\u001b[A\n",
      " 66%|██████▋   | 274656/414113 [00:57<00:29, 4806.95it/s]\u001b[A\n",
      " 66%|██████▋   | 275144/414113 [00:58<00:28, 4827.25it/s]\u001b[A\n",
      " 67%|██████▋   | 275627/414113 [00:58<00:28, 4824.64it/s]\u001b[A\n",
      " 67%|██████▋   | 276110/414113 [00:58<00:28, 4800.59it/s]\u001b[A\n",
      " 67%|██████▋   | 276591/414113 [00:58<00:28, 4768.95it/s]\u001b[A\n",
      " 67%|██████▋   | 277069/414113 [00:58<00:28, 4740.07it/s]\u001b[A\n",
      " 67%|██████▋   | 277561/414113 [00:58<00:28, 4788.62it/s]\u001b[A\n",
      " 67%|██████▋   | 278046/414113 [00:58<00:28, 4805.55it/s]\u001b[A\n",
      " 67%|██████▋   | 278527/414113 [00:58<00:28, 4792.88it/s]\u001b[A\n",
      " 67%|██████▋   | 279007/414113 [00:58<00:28, 4786.08it/s]\u001b[A\n",
      " 67%|██████▋   | 279494/414113 [00:58<00:27, 4808.58it/s]\u001b[A\n",
      " 68%|██████▊   | 279975/414113 [00:59<00:27, 4796.56it/s]\u001b[A\n",
      " 68%|██████▊   | 280455/414113 [00:59<00:27, 4788.35it/s]\u001b[A\n",
      " 68%|██████▊   | 280941/414113 [00:59<00:27, 4807.97it/s]\u001b[A\n",
      " 68%|██████▊   | 281422/414113 [00:59<00:27, 4791.53it/s]\u001b[A\n",
      " 68%|██████▊   | 281910/414113 [00:59<00:27, 4817.07it/s]\u001b[A\n",
      " 68%|██████▊   | 282392/414113 [00:59<00:27, 4815.20it/s]\u001b[A\n",
      " 68%|██████▊   | 282874/414113 [00:59<00:27, 4794.86it/s]\u001b[A\n",
      " 68%|██████▊   | 283361/414113 [00:59<00:27, 4812.85it/s]\u001b[A\n",
      " 69%|██████▊   | 283851/414113 [00:59<00:26, 4833.95it/s]\u001b[A\n",
      " 69%|██████▊   | 284339/414113 [00:59<00:26, 4846.13it/s]\u001b[A\n",
      " 69%|██████▉   | 284843/414113 [01:00<00:26, 4900.38it/s]\u001b[A\n",
      " 69%|██████▉   | 285334/414113 [01:00<00:26, 4901.53it/s]\u001b[A\n",
      " 69%|██████▉   | 285830/414113 [01:00<00:26, 4918.90it/s]\u001b[A\n",
      " 69%|██████▉   | 286322/414113 [01:00<00:26, 4913.27it/s]\u001b[A\n",
      " 69%|██████▉   | 286820/414113 [01:00<00:25, 4932.82it/s]\u001b[A\n",
      " 69%|██████▉   | 287314/414113 [01:00<00:25, 4912.73it/s]\u001b[A\n",
      " 69%|██████▉   | 287806/414113 [01:00<00:25, 4885.03it/s]\u001b[A\n",
      " 70%|██████▉   | 288302/414113 [01:00<00:25, 4905.69it/s]\u001b[A\n",
      " 70%|██████▉   | 288795/414113 [01:00<00:25, 4910.33it/s]\u001b[A\n",
      " 70%|██████▉   | 289287/414113 [01:00<00:25, 4889.38it/s]\u001b[A\n",
      " 70%|██████▉   | 289776/414113 [01:01<00:25, 4868.58it/s]\u001b[A\n",
      " 70%|███████   | 290265/414113 [01:01<00:25, 4872.88it/s]\u001b[A\n",
      " 70%|███████   | 290758/414113 [01:01<00:25, 4888.21it/s]\u001b[A\n",
      " 70%|███████   | 291247/414113 [01:01<00:25, 4853.93it/s]\u001b[A\n",
      " 70%|███████   | 291733/414113 [01:01<00:25, 4825.87it/s]\u001b[A\n",
      " 71%|███████   | 292232/414113 [01:01<00:25, 4871.42it/s]\u001b[A\n",
      " 71%|███████   | 292720/414113 [01:01<00:25, 4854.42it/s]\u001b[A\n",
      " 71%|███████   | 293208/414113 [01:01<00:24, 4859.71it/s]\u001b[A\n",
      " 71%|███████   | 293695/414113 [01:01<00:24, 4849.67it/s]\u001b[A\n",
      " 71%|███████   | 294181/414113 [01:02<00:43, 2766.11it/s]\u001b[A\n",
      " 71%|███████   | 294668/414113 [01:02<00:37, 3176.84it/s]\u001b[A\n",
      " 71%|███████▏  | 295154/414113 [01:02<00:33, 3544.67it/s]\u001b[A\n",
      " 71%|███████▏  | 295641/414113 [01:02<00:30, 3858.98it/s]\u001b[A\n",
      " 72%|███████▏  | 296124/414113 [01:02<00:28, 4106.15it/s]\u001b[A\n",
      " 72%|███████▏  | 296587/414113 [01:02<00:27, 4250.05it/s]\u001b[A\n",
      " 72%|███████▏  | 297073/414113 [01:02<00:26, 4414.74it/s]\u001b[A\n",
      " 72%|███████▏  | 297552/414113 [01:02<00:25, 4518.34it/s]\u001b[A\n",
      " 72%|███████▏  | 298035/414113 [01:03<00:25, 4605.28it/s]\u001b[A\n",
      " 72%|███████▏  | 298520/414113 [01:03<00:24, 4675.67it/s]\u001b[A\n",
      " 72%|███████▏  | 299006/414113 [01:03<00:24, 4728.43it/s]\u001b[A\n",
      " 72%|███████▏  | 299495/414113 [01:03<00:24, 4773.28it/s]\u001b[A\n",
      " 72%|███████▏  | 299980/414113 [01:03<00:23, 4794.16it/s]\u001b[A\n",
      " 73%|███████▎  | 300464/414113 [01:03<00:23, 4800.41it/s]\u001b[A\n",
      " 73%|███████▎  | 300947/414113 [01:03<00:23, 4808.35it/s]\u001b[A\n",
      " 73%|███████▎  | 301433/414113 [01:03<00:23, 4822.74it/s]\u001b[A\n",
      " 73%|███████▎  | 301940/414113 [01:03<00:22, 4894.23it/s]\u001b[A\n",
      " 73%|███████▎  | 302431/414113 [01:03<00:23, 4833.05it/s]\u001b[A\n",
      " 73%|███████▎  | 302916/414113 [01:04<00:23, 4832.25it/s]\u001b[A\n",
      " 73%|███████▎  | 303400/414113 [01:04<00:22, 4824.40it/s]\u001b[A\n",
      " 73%|███████▎  | 303883/414113 [01:04<00:23, 4621.79it/s]\u001b[A\n",
      " 73%|███████▎  | 304367/414113 [01:04<00:23, 4684.46it/s]\u001b[A\n",
      " 74%|███████▎  | 304840/414113 [01:04<00:23, 4697.15it/s]\u001b[A\n",
      " 74%|███████▎  | 305311/414113 [01:04<00:23, 4696.79it/s]\u001b[A\n",
      " 74%|███████▍  | 305791/414113 [01:04<00:22, 4725.07it/s]\u001b[A\n",
      " 74%|███████▍  | 306265/414113 [01:04<00:22, 4729.52it/s]\u001b[A\n",
      " 74%|███████▍  | 306749/414113 [01:04<00:22, 4761.12it/s]\u001b[A\n",
      " 74%|███████▍  | 307238/414113 [01:04<00:22, 4797.15it/s]\u001b[A\n",
      " 74%|███████▍  | 307719/414113 [01:05<00:22, 4756.45it/s]\u001b[A\n",
      " 74%|███████▍  | 308212/414113 [01:05<00:22, 4806.64it/s]\u001b[A\n",
      " 75%|███████▍  | 308695/414113 [01:05<00:21, 4813.10it/s]\u001b[A\n",
      " 75%|███████▍  | 309177/414113 [01:05<00:21, 4806.28it/s]\u001b[A\n",
      " 75%|███████▍  | 309666/414113 [01:05<00:21, 4830.22it/s]\u001b[A\n",
      " 75%|███████▍  | 310158/414113 [01:05<00:21, 4856.07it/s]\u001b[A\n",
      " 75%|███████▌  | 310644/414113 [01:05<00:21, 4841.46it/s]\u001b[A\n",
      " 75%|███████▌  | 311129/414113 [01:05<00:21, 4796.72it/s]\u001b[A\n",
      " 75%|███████▌  | 311609/414113 [01:05<00:22, 4617.50it/s]\u001b[A\n",
      " 75%|███████▌  | 312073/414113 [01:06<00:22, 4584.47it/s]\u001b[A\n",
      " 75%|███████▌  | 312555/414113 [01:06<00:21, 4650.01it/s]\u001b[A\n",
      " 76%|███████▌  | 313038/414113 [01:06<00:21, 4701.43it/s]\u001b[A\n",
      " 76%|███████▌  | 313518/414113 [01:06<00:21, 4729.44it/s]\u001b[A\n",
      " 76%|███████▌  | 313992/414113 [01:06<00:21, 4715.66it/s]\u001b[A\n",
      " 76%|███████▌  | 314479/414113 [01:06<00:20, 4760.23it/s]\u001b[A\n",
      " 76%|███████▌  | 314960/414113 [01:06<00:20, 4772.54it/s]\u001b[A\n",
      " 76%|███████▌  | 315438/414113 [01:06<00:20, 4763.16it/s]\u001b[A\n",
      " 76%|███████▋  | 315924/414113 [01:06<00:20, 4790.23it/s]\u001b[A\n",
      " 76%|███████▋  | 316417/414113 [01:06<00:20, 4829.49it/s]\u001b[A\n",
      " 77%|███████▋  | 316918/414113 [01:07<00:19, 4880.56it/s]\u001b[A\n",
      " 77%|███████▋  | 317411/414113 [01:07<00:19, 4893.26it/s]\u001b[A\n",
      " 77%|███████▋  | 317901/414113 [01:07<00:19, 4893.42it/s]\u001b[A\n",
      " 77%|███████▋  | 318391/414113 [01:07<00:19, 4892.22it/s]\u001b[A\n",
      " 77%|███████▋  | 318881/414113 [01:07<00:19, 4877.58it/s]\u001b[A\n",
      " 77%|███████▋  | 319369/414113 [01:07<00:19, 4838.83it/s]\u001b[A\n",
      " 77%|███████▋  | 319854/414113 [01:07<00:19, 4841.98it/s]\u001b[A\n",
      " 77%|███████▋  | 320346/414113 [01:07<00:19, 4863.13it/s]\u001b[A\n",
      " 77%|███████▋  | 320834/414113 [01:07<00:19, 4866.69it/s]\u001b[A\n",
      " 78%|███████▊  | 321333/414113 [01:07<00:18, 4901.04it/s]\u001b[A\n",
      " 78%|███████▊  | 321838/414113 [01:08<00:18, 4942.94it/s]\u001b[A\n",
      " 78%|███████▊  | 322333/414113 [01:08<00:18, 4933.63it/s]\u001b[A\n",
      " 78%|███████▊  | 322827/414113 [01:08<00:18, 4929.71it/s]\u001b[A\n",
      " 78%|███████▊  | 323321/414113 [01:08<00:18, 4920.04it/s]\u001b[A\n",
      " 78%|███████▊  | 323814/414113 [01:08<00:18, 4889.61it/s]\u001b[A\n",
      " 78%|███████▊  | 324304/414113 [01:08<00:18, 4860.78it/s]\u001b[A\n",
      " 78%|███████▊  | 324803/414113 [01:08<00:18, 4897.78it/s]\u001b[A\n",
      " 79%|███████▊  | 325293/414113 [01:08<00:18, 4862.91it/s]\u001b[A\n",
      " 79%|███████▊  | 325782/414113 [01:08<00:18, 4868.56it/s]\u001b[A\n",
      " 79%|███████▉  | 326269/414113 [01:08<00:18, 4863.41it/s]\u001b[A\n",
      " 79%|███████▉  | 326756/414113 [01:09<00:17, 4864.00it/s]\u001b[A\n",
      " 79%|███████▉  | 327249/414113 [01:09<00:17, 4881.21it/s]\u001b[A\n",
      " 79%|███████▉  | 327738/414113 [01:09<00:17, 4822.11it/s]\u001b[A\n",
      " 79%|███████▉  | 328221/414113 [01:09<00:17, 4812.24it/s]\u001b[A\n",
      " 79%|███████▉  | 328703/414113 [01:09<00:17, 4791.24it/s]\u001b[A\n",
      " 79%|███████▉  | 329184/414113 [01:09<00:17, 4796.32it/s]\u001b[A\n",
      " 80%|███████▉  | 329664/414113 [01:09<00:17, 4763.12it/s]\u001b[A\n",
      " 80%|███████▉  | 330142/414113 [01:09<00:17, 4767.64it/s]\u001b[A\n",
      " 80%|███████▉  | 330619/414113 [01:09<00:17, 4752.79it/s]\u001b[A\n",
      " 80%|███████▉  | 331095/414113 [01:09<00:17, 4743.08it/s]\u001b[A\n",
      " 80%|████████  | 331586/414113 [01:10<00:17, 4790.40it/s]\u001b[A\n",
      " 80%|████████  | 332073/414113 [01:10<00:17, 4811.43it/s]\u001b[A\n",
      " 80%|████████  | 332555/414113 [01:10<00:16, 4804.02it/s]\u001b[A\n",
      " 80%|████████  | 333040/414113 [01:10<00:16, 4816.65it/s]\u001b[A\n",
      " 81%|████████  | 333522/414113 [01:10<00:16, 4808.43it/s]\u001b[A\n",
      " 81%|████████  | 334005/414113 [01:10<00:16, 4813.03it/s]\u001b[A\n",
      " 81%|████████  | 334487/414113 [01:10<00:16, 4791.60it/s]\u001b[A\n",
      " 81%|████████  | 334967/414113 [01:10<00:16, 4779.55it/s]\u001b[A\n",
      " 81%|████████  | 335445/414113 [01:10<00:16, 4749.99it/s]\u001b[A\n",
      " 81%|████████  | 335921/414113 [01:10<00:16, 4724.40it/s]\u001b[A\n",
      " 81%|████████  | 336401/414113 [01:11<00:16, 4746.32it/s]\u001b[A\n",
      " 81%|████████▏ | 336876/414113 [01:11<00:16, 4733.51it/s]\u001b[A\n",
      " 81%|████████▏ | 337350/414113 [01:11<00:16, 4724.38it/s]\u001b[A\n",
      " 82%|████████▏ | 337829/414113 [01:11<00:16, 4743.07it/s]\u001b[A\n",
      " 82%|████████▏ | 338304/414113 [01:11<00:16, 4718.23it/s]\u001b[A\n",
      " 82%|████████▏ | 338776/414113 [01:11<00:16, 4690.07it/s]\u001b[A\n",
      " 82%|████████▏ | 339253/414113 [01:11<00:15, 4711.13it/s]\u001b[A\n",
      " 82%|████████▏ | 339725/414113 [01:11<00:15, 4702.16it/s]\u001b[A\n",
      " 82%|████████▏ | 340196/414113 [01:11<00:15, 4700.05it/s]\u001b[A\n",
      " 82%|████████▏ | 340672/414113 [01:11<00:15, 4717.76it/s]\u001b[A\n",
      " 82%|████████▏ | 341150/414113 [01:12<00:15, 4734.98it/s]\u001b[A\n",
      " 82%|████████▏ | 341624/414113 [01:12<00:15, 4732.32it/s]\u001b[A\n",
      " 83%|████████▎ | 342101/414113 [01:12<00:15, 4743.11it/s]\u001b[A\n",
      " 83%|████████▎ | 342576/414113 [01:12<00:15, 4741.84it/s]\u001b[A\n",
      " 83%|████████▎ | 343051/414113 [01:12<00:15, 4720.83it/s]\u001b[A\n",
      " 83%|████████▎ | 343533/414113 [01:12<00:14, 4749.58it/s]\u001b[A\n",
      " 83%|████████▎ | 344017/414113 [01:12<00:14, 4775.52it/s]\u001b[A\n",
      " 83%|████████▎ | 344495/414113 [01:12<00:14, 4746.66it/s]\u001b[A\n",
      " 83%|████████▎ | 344970/414113 [01:12<00:14, 4733.93it/s]\u001b[A\n",
      " 83%|████████▎ | 345459/414113 [01:12<00:14, 4778.03it/s]\u001b[A\n",
      " 84%|████████▎ | 345942/414113 [01:13<00:14, 4790.80it/s]\u001b[A\n",
      " 84%|████████▎ | 346422/414113 [01:13<00:14, 4783.49it/s]\u001b[A\n",
      " 84%|████████▍ | 346901/414113 [01:13<00:14, 4781.74it/s]\u001b[A\n",
      " 84%|████████▍ | 347380/414113 [01:13<00:14, 4737.42it/s]\u001b[A\n",
      " 84%|████████▍ | 347856/414113 [01:13<00:13, 4741.20it/s]\u001b[A\n",
      " 84%|████████▍ | 348331/414113 [01:13<00:14, 4688.84it/s]\u001b[A\n",
      " 84%|████████▍ | 348813/414113 [01:13<00:13, 4726.86it/s]\u001b[A\n",
      " 84%|████████▍ | 349293/414113 [01:13<00:13, 4747.97it/s]\u001b[A\n",
      " 84%|████████▍ | 349779/414113 [01:13<00:13, 4779.23it/s]\u001b[A\n",
      " 85%|████████▍ | 350264/414113 [01:13<00:13, 4798.70it/s]\u001b[A\n",
      " 85%|████████▍ | 350756/414113 [01:14<00:13, 4832.23it/s]\u001b[A\n",
      " 85%|████████▍ | 351244/414113 [01:14<00:12, 4843.26it/s]\u001b[A\n",
      " 85%|████████▍ | 351729/414113 [01:14<00:12, 4831.60it/s]\u001b[A\n",
      " 85%|████████▌ | 352213/414113 [01:14<00:12, 4828.36it/s]\u001b[A\n",
      " 85%|████████▌ | 352696/414113 [01:14<00:12, 4785.79it/s]\u001b[A\n",
      " 85%|████████▌ | 353175/414113 [01:14<00:12, 4776.35it/s]\u001b[A\n",
      " 85%|████████▌ | 353658/414113 [01:14<00:12, 4790.68it/s]\u001b[A\n",
      " 86%|████████▌ | 354138/414113 [01:14<00:12, 4773.33it/s]\u001b[A\n",
      " 86%|████████▌ | 354616/414113 [01:14<00:13, 4398.53it/s]\u001b[A\n",
      " 86%|████████▌ | 355062/414113 [01:15<00:13, 4283.25it/s]\u001b[A\n",
      " 86%|████████▌ | 355557/414113 [01:15<00:13, 4462.67it/s]\u001b[A\n",
      " 86%|████████▌ | 356024/414113 [01:15<00:12, 4520.05it/s]\u001b[A\n",
      " 86%|████████▌ | 356508/414113 [01:15<00:12, 4608.92it/s]\u001b[A\n",
      " 86%|████████▌ | 356977/414113 [01:15<00:12, 4631.50it/s]\u001b[A\n",
      " 86%|████████▋ | 357445/414113 [01:15<00:12, 4642.39it/s]\u001b[A\n",
      " 86%|████████▋ | 357934/414113 [01:15<00:11, 4711.63it/s]\u001b[A\n",
      " 87%|████████▋ | 358411/414113 [01:15<00:11, 4728.82it/s]\u001b[A\n",
      " 87%|████████▋ | 358892/414113 [01:15<00:11, 4752.04it/s]\u001b[A\n",
      " 87%|████████▋ | 359368/414113 [01:15<00:11, 4705.25it/s]\u001b[A\n",
      " 87%|████████▋ | 359843/414113 [01:16<00:11, 4716.19it/s]\u001b[A\n",
      " 87%|████████▋ | 360328/414113 [01:16<00:11, 4754.36it/s]\u001b[A\n",
      " 87%|████████▋ | 360804/414113 [01:16<00:11, 4746.44it/s]\u001b[A\n",
      " 87%|████████▋ | 361279/414113 [01:16<00:11, 4721.20it/s]\u001b[A\n",
      " 87%|████████▋ | 361763/414113 [01:16<00:11, 4755.85it/s]\u001b[A\n",
      " 87%|████████▋ | 362239/414113 [01:16<00:10, 4750.34it/s]\u001b[A\n",
      " 88%|████████▊ | 362717/414113 [01:16<00:10, 4756.28it/s]\u001b[A\n",
      " 88%|████████▊ | 363194/414113 [01:16<00:10, 4758.34it/s]\u001b[A\n",
      " 88%|████████▊ | 363670/414113 [01:16<00:10, 4696.47it/s]\u001b[A\n",
      " 88%|████████▊ | 364140/414113 [01:16<00:10, 4674.35it/s]\u001b[A\n",
      " 88%|████████▊ | 364615/414113 [01:17<00:10, 4695.13it/s]\u001b[A\n",
      " 88%|████████▊ | 365099/414113 [01:17<00:10, 4736.88it/s]\u001b[A\n",
      " 88%|████████▊ | 365574/414113 [01:17<00:10, 4739.37it/s]\u001b[A\n",
      " 88%|████████▊ | 366061/414113 [01:17<00:10, 4777.56it/s]\u001b[A\n",
      " 89%|████████▊ | 366539/414113 [01:17<00:09, 4768.20it/s]\u001b[A\n",
      " 89%|████████▊ | 367016/414113 [01:17<00:10, 4705.78it/s]\u001b[A\n",
      " 89%|████████▊ | 367506/414113 [01:17<00:09, 4761.34it/s]\u001b[A\n",
      " 89%|████████▉ | 367983/414113 [01:17<00:09, 4723.29it/s]\u001b[A\n",
      " 89%|████████▉ | 368465/414113 [01:17<00:09, 4751.58it/s]\u001b[A\n",
      " 89%|████████▉ | 368941/414113 [01:17<00:09, 4737.74it/s]\u001b[A\n",
      " 89%|████████▉ | 369421/414113 [01:18<00:09, 4756.04it/s]\u001b[A\n",
      " 89%|████████▉ | 369897/414113 [01:18<00:09, 4714.45it/s]\u001b[A\n",
      " 89%|████████▉ | 370369/414113 [01:18<00:09, 4705.81it/s]\u001b[A\n",
      " 90%|████████▉ | 370840/414113 [01:18<00:09, 4646.66it/s]\u001b[A\n",
      " 90%|████████▉ | 371305/414113 [01:18<00:09, 4639.09it/s]\u001b[A\n",
      " 90%|████████▉ | 371770/414113 [01:18<00:09, 4632.03it/s]\u001b[A\n",
      " 90%|████████▉ | 372243/414113 [01:18<00:08, 4659.13it/s]\u001b[A\n",
      " 90%|█████████ | 372710/414113 [01:18<00:08, 4631.59it/s]\u001b[A\n",
      " 90%|█████████ | 373194/414113 [01:18<00:08, 4688.73it/s]\u001b[A\n",
      " 90%|█████████ | 373664/414113 [01:18<00:08, 4678.10it/s]\u001b[A\n",
      " 90%|█████████ | 374132/414113 [01:19<00:08, 4678.25it/s]\u001b[A\n",
      " 90%|█████████ | 374607/414113 [01:19<00:08, 4698.00it/s]\u001b[A\n",
      " 91%|█████████ | 375077/414113 [01:19<00:08, 4691.99it/s]\u001b[A\n",
      " 91%|█████████ | 375548/414113 [01:19<00:08, 4694.80it/s]\u001b[A\n",
      " 91%|█████████ | 376027/414113 [01:19<00:08, 4722.47it/s]\u001b[A\n",
      " 91%|█████████ | 376505/414113 [01:19<00:07, 4739.31it/s]\u001b[A\n",
      " 91%|█████████ | 376988/414113 [01:19<00:07, 4763.87it/s]\u001b[A\n",
      " 91%|█████████ | 377465/414113 [01:19<00:07, 4705.25it/s]\u001b[A\n",
      " 91%|█████████▏| 377953/414113 [01:19<00:07, 4754.67it/s]\u001b[A\n",
      " 91%|█████████▏| 378437/414113 [01:19<00:07, 4776.97it/s]\u001b[A\n",
      " 92%|█████████▏| 378921/414113 [01:20<00:07, 4795.10it/s]\u001b[A\n",
      " 92%|█████████▏| 379401/414113 [01:20<00:07, 4787.41it/s]\u001b[A\n",
      " 92%|█████████▏| 379880/414113 [01:20<00:07, 4781.13it/s]\u001b[A\n",
      " 92%|█████████▏| 380363/414113 [01:20<00:07, 4794.75it/s]\u001b[A\n",
      " 92%|█████████▏| 380843/414113 [01:20<00:06, 4788.68it/s]\u001b[A\n",
      " 92%|█████████▏| 381342/414113 [01:20<00:06, 4845.89it/s]\u001b[A\n",
      " 92%|█████████▏| 381827/414113 [01:20<00:06, 4820.21it/s]\u001b[A\n",
      " 92%|█████████▏| 382310/414113 [01:20<00:06, 4822.26it/s]\u001b[A\n",
      " 92%|█████████▏| 382796/414113 [01:20<00:06, 4833.24it/s]\u001b[A\n",
      " 93%|█████████▎| 383296/414113 [01:20<00:06, 4881.78it/s]\u001b[A\n",
      " 93%|█████████▎| 383797/414113 [01:21<00:06, 4917.31it/s]\u001b[A\n",
      " 93%|█████████▎| 384289/414113 [01:21<00:06, 4854.12it/s]\u001b[A\n",
      " 93%|█████████▎| 384775/414113 [01:21<00:06, 4792.07it/s]\u001b[A\n",
      " 93%|█████████▎| 385255/414113 [01:21<00:06, 4753.76it/s]\u001b[A\n",
      " 93%|█████████▎| 385731/414113 [01:21<00:05, 4742.73it/s]\u001b[A\n",
      " 93%|█████████▎| 386206/414113 [01:21<00:05, 4739.39it/s]\u001b[A\n",
      " 93%|█████████▎| 386683/414113 [01:21<00:05, 4747.66it/s]\u001b[A\n",
      " 93%|█████████▎| 387158/414113 [01:21<00:05, 4740.59it/s]\u001b[A\n",
      " 94%|█████████▎| 387646/414113 [01:21<00:05, 4781.55it/s]\u001b[A\n",
      " 94%|█████████▎| 388125/414113 [01:21<00:05, 4416.29it/s]\u001b[A\n",
      " 94%|█████████▍| 388615/414113 [01:22<00:05, 4549.69it/s]\u001b[A\n",
      " 94%|█████████▍| 389122/414113 [01:22<00:05, 4691.82it/s]\u001b[A\n",
      " 94%|█████████▍| 389604/414113 [01:22<00:05, 4728.29it/s]\u001b[A\n",
      " 94%|█████████▍| 390083/414113 [01:22<00:05, 4744.15it/s]\u001b[A\n",
      " 94%|█████████▍| 390573/414113 [01:22<00:04, 4787.18it/s]\u001b[A\n",
      " 94%|█████████▍| 391054/414113 [01:22<00:04, 4761.93it/s]\u001b[A\n",
      " 95%|█████████▍| 391546/414113 [01:22<00:04, 4806.54it/s]\u001b[A\n",
      " 95%|█████████▍| 392039/414113 [01:22<00:04, 4840.51it/s]\u001b[A\n",
      " 95%|█████████▍| 392527/414113 [01:22<00:04, 4852.09it/s]\u001b[A\n",
      " 95%|█████████▍| 393013/414113 [01:22<00:04, 4831.33it/s]\u001b[A\n",
      " 95%|█████████▌| 393498/414113 [01:23<00:04, 4835.16it/s]\u001b[A\n",
      " 95%|█████████▌| 393982/414113 [01:23<00:04, 4819.33it/s]\u001b[A\n",
      " 95%|█████████▌| 394465/414113 [01:23<00:04, 4771.85it/s]\u001b[A\n",
      " 95%|█████████▌| 394948/414113 [01:23<00:04, 4788.77it/s]\u001b[A\n",
      " 95%|█████████▌| 395428/414113 [01:23<00:03, 4744.76it/s]\u001b[A\n",
      " 96%|█████████▌| 395903/414113 [01:23<00:03, 4743.43it/s]\u001b[A\n",
      " 96%|█████████▌| 396391/414113 [01:23<00:03, 4780.83it/s]\u001b[A\n",
      " 96%|█████████▌| 396873/414113 [01:23<00:03, 4792.44it/s]\u001b[A\n",
      " 96%|█████████▌| 397362/414113 [01:23<00:03, 4820.98it/s]\u001b[A\n",
      " 96%|█████████▌| 397845/414113 [01:24<00:03, 4818.27it/s]\u001b[A\n",
      " 96%|█████████▌| 398332/414113 [01:24<00:03, 4831.85it/s]\u001b[A\n",
      " 96%|█████████▋| 398816/414113 [01:24<00:03, 4821.61it/s]\u001b[A\n",
      " 96%|█████████▋| 399299/414113 [01:24<00:03, 4811.96it/s]\u001b[A\n",
      " 97%|█████████▋| 399781/414113 [01:24<00:03, 4750.49it/s]\u001b[A\n",
      " 97%|█████████▋| 400265/414113 [01:24<00:02, 4775.31it/s]\u001b[A\n",
      " 97%|█████████▋| 400743/414113 [01:24<00:02, 4748.45it/s]\u001b[A\n",
      " 97%|█████████▋| 401220/414113 [01:24<00:02, 4753.54it/s]\u001b[A\n",
      " 97%|█████████▋| 401707/414113 [01:24<00:02, 4786.90it/s]\u001b[A\n",
      " 97%|█████████▋| 402193/414113 [01:24<00:02, 4805.87it/s]\u001b[A\n",
      " 97%|█████████▋| 402674/414113 [01:25<00:02, 4788.20it/s]\u001b[A\n",
      " 97%|█████████▋| 403160/414113 [01:25<00:02, 4808.93it/s]\u001b[A\n",
      " 97%|█████████▋| 403641/414113 [01:25<00:02, 4766.99it/s]\u001b[A\n",
      " 98%|█████████▊| 404136/414113 [01:25<00:02, 4820.06it/s]\u001b[A\n",
      " 98%|█████████▊| 404619/414113 [01:25<00:01, 4801.55it/s]\u001b[A\n",
      " 98%|█████████▊| 405100/414113 [01:25<00:01, 4772.68it/s]\u001b[A\n",
      " 98%|█████████▊| 405582/414113 [01:25<00:01, 4785.90it/s]\u001b[A\n",
      " 98%|█████████▊| 406061/414113 [01:25<00:01, 4580.13it/s]\u001b[A\n",
      " 98%|█████████▊| 406544/414113 [01:25<00:01, 4650.91it/s]\u001b[A\n",
      " 98%|█████████▊| 407016/414113 [01:25<00:01, 4670.73it/s]\u001b[A\n",
      " 98%|█████████▊| 407500/414113 [01:26<00:01, 4719.55it/s]\u001b[A\n",
      " 99%|█████████▊| 407980/414113 [01:26<00:01, 4740.73it/s]\u001b[A\n",
      " 99%|█████████▊| 408457/414113 [01:26<00:01, 4748.91it/s]\u001b[A\n",
      " 99%|█████████▊| 408933/414113 [01:26<00:01, 4744.77it/s]\u001b[A\n",
      " 99%|█████████▉| 409408/414113 [01:26<00:00, 4741.41it/s]\u001b[A\n",
      " 99%|█████████▉| 409883/414113 [01:26<00:00, 4742.16it/s]\u001b[A\n",
      " 99%|█████████▉| 410370/414113 [01:26<00:00, 4778.26it/s]\u001b[A\n",
      " 99%|█████████▉| 410853/414113 [01:26<00:00, 4791.15it/s]\u001b[A\n",
      " 99%|█████████▉| 411341/414113 [01:26<00:00, 4815.29it/s]\u001b[A\n",
      " 99%|█████████▉| 411828/414113 [01:26<00:00, 4829.29it/s]\u001b[A\n",
      "100%|█████████▉| 412322/414113 [01:27<00:00, 4860.06it/s]\u001b[A\n",
      "100%|█████████▉| 412814/414113 [01:27<00:00, 4876.80it/s]\u001b[A\n",
      "100%|█████████▉| 413302/414113 [01:27<00:00, 4875.36it/s]\u001b[A\n",
      "100%|█████████▉| 413790/414113 [01:27<00:00, 4857.09it/s]\u001b[A\n",
      "100%|██████████| 414113/414113 [01:27<00:00, 4737.34it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.99s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from data_loader import get_loader\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "import math\n",
    "\n",
    "\n",
    "## TODO #1: Select appropriate values for the Python variables below.\n",
    "batch_size = 64          # batch size\n",
    "vocab_threshold = 5        # minimum word count threshold\n",
    "vocab_from_file = True    # if True, load existing vocab file\n",
    "embed_size = 512           # dimensionality of image and word embeddings\n",
    "hidden_size = 512          # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3             # number of training epochs\n",
    "save_every = 1             # determines frequency of saving model weights\n",
    "print_every = 100          # determines window for printing average loss\n",
    "log_file = 'training_log.txt'       # name of file with saved training loss and perplexity\n",
    "\n",
    "# (Optional) TODO #2: Amend the image transform below.\n",
    "transform_train = transforms.Compose([ \n",
    "    transforms.Resize(256),                          # smaller edge of image resized to 256\n",
    "    transforms.RandomCrop(224),                      # get 224x224 crop from random location\n",
    "    transforms.RandomHorizontalFlip(),               # horizontally flip image with probability=0.5\n",
    "    transforms.ToTensor(),                           # convert the PIL Image to a tensor\n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      # normalize image for pre-trained model\n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "# Build data loader.\n",
    "data_loader = get_loader(transform=transform_train,\n",
    "                         mode='train',\n",
    "                         batch_size=batch_size,\n",
    "                         vocab_threshold=vocab_threshold,\n",
    "                         vocab_from_file=vocab_from_file)\n",
    "\n",
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "\n",
    "# Initialize the encoder and decoder. \n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to GPU if CUDA is available. \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Define the loss function. \n",
    "criterion = nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO #3: Specify the learnable parameters of the model.\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# TODO #4: Define the optimizer.\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "# Set the total number of training steps per epoch.\n",
    "total_step = math.ceil(len(data_loader.dataset.caption_lengths) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step2'></a>\n",
    "## Step 2: Train your Model\n",
    "\n",
    "Once you have executed the code cell in **Step 1**, the training procedure below should run without issue.  \n",
    "\n",
    "It is completely fine to leave the code cell below as-is without modifications to train your model.  However, if you would like to modify the code used to train the model below, you must ensure that your changes are easily parsed by your reviewer.  In other words, make sure to provide appropriate comments to describe how your code works!  \n",
    "\n",
    "You may find it useful to load saved weights to resume training.  In that case, note the names of the files containing the encoder and decoder weights that you'd like to load (`encoder_file` and `decoder_file`).  Then you can load the weights by using the lines below:\n",
    "\n",
    "```python\n",
    "# Load pre-trained weights before resuming training.\n",
    "encoder.load_state_dict(torch.load(os.path.join('./models', encoder_file)))\n",
    "decoder.load_state_dict(torch.load(os.path.join('./models', decoder_file)))\n",
    "```\n",
    "\n",
    "While trying out parameters, make sure to take extensive notes and record the settings that you used in your various training runs.  In particular, you don't want to encounter a situation where you've trained a model for several hours but can't remember what settings you used :).\n",
    "\n",
    "### A Note on Tuning Hyperparameters\n",
    "\n",
    "To figure out how well your model is doing, you can look at how the training loss and perplexity evolve during training - and for the purposes of this project, you are encouraged to amend the hyperparameters based on this information.  \n",
    "\n",
    "However, this will not tell you if your model is overfitting to the training data, and, unfortunately, overfitting is a problem that is commonly encountered when training image captioning models.  \n",
    "\n",
    "For this project, you need not worry about overfitting. **This project does not have strict requirements regarding the performance of your model**, and you just need to demonstrate that your model has learned **_something_** when you generate captions on the test data.  For now, we strongly encourage you to train your model for the suggested 3 epochs without worrying about performance; then, you should immediately transition to the next notebook in the sequence (**3_Inference.ipynb**) to see how your model performs on the test data.  If your model needs to be changed, you can come back to this notebook, amend hyperparameters (if necessary), and re-train the model.\n",
    "\n",
    "That said, if you would like to go above and beyond in this project, you can read about some approaches to minimizing overfitting in section 4.3.1 of [this paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7505636).  In the next (optional) step of this notebook, we provide some guidance for assessing the performance on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/6471], Loss: 3.6668, Perplexity: 39.1248\n",
      "Epoch [1/3], Step [200/6471], Loss: 3.2994, Perplexity: 27.0961\n",
      "Epoch [1/3], Step [300/6471], Loss: 3.1509, Perplexity: 23.35800\n",
      "Epoch [1/3], Step [400/6471], Loss: 2.9566, Perplexity: 19.2324\n",
      "Epoch [1/3], Step [500/6471], Loss: 3.1651, Perplexity: 23.6901\n",
      "Epoch [1/3], Step [600/6471], Loss: 2.8960, Perplexity: 18.1012\n",
      "Epoch [1/3], Step [700/6471], Loss: 2.9764, Perplexity: 19.6167\n",
      "Epoch [1/3], Step [800/6471], Loss: 2.7536, Perplexity: 15.6998\n",
      "Epoch [1/3], Step [900/6471], Loss: 2.6251, Perplexity: 13.8055\n",
      "Epoch [1/3], Step [1000/6471], Loss: 2.6443, Perplexity: 14.0732\n",
      "Epoch [1/3], Step [1100/6471], Loss: 2.7546, Perplexity: 15.7151\n",
      "Epoch [1/3], Step [1200/6471], Loss: 2.9462, Perplexity: 19.0337\n",
      "Epoch [1/3], Step [1300/6471], Loss: 2.4800, Perplexity: 11.9418\n",
      "Epoch [1/3], Step [1400/6471], Loss: 2.3909, Perplexity: 10.9234\n",
      "Epoch [1/3], Step [1500/6471], Loss: 2.7680, Perplexity: 15.9272\n",
      "Epoch [1/3], Step [1600/6471], Loss: 3.2562, Perplexity: 25.9504\n",
      "Epoch [1/3], Step [1700/6471], Loss: 2.7529, Perplexity: 15.6883\n",
      "Epoch [1/3], Step [1800/6471], Loss: 2.3899, Perplexity: 10.9129\n",
      "Epoch [1/3], Step [1900/6471], Loss: 2.2704, Perplexity: 9.68284\n",
      "Epoch [1/3], Step [2000/6471], Loss: 2.4454, Perplexity: 11.5347\n",
      "Epoch [1/3], Step [2100/6471], Loss: 2.5456, Perplexity: 12.7507\n",
      "Epoch [1/3], Step [2200/6471], Loss: 2.3189, Perplexity: 10.1646\n",
      "Epoch [1/3], Step [2300/6471], Loss: 2.2690, Perplexity: 9.66957\n",
      "Epoch [1/3], Step [2400/6471], Loss: 2.2432, Perplexity: 9.42386\n",
      "Epoch [1/3], Step [2500/6471], Loss: 2.3716, Perplexity: 10.7146\n",
      "Epoch [1/3], Step [2600/6471], Loss: 2.1619, Perplexity: 8.68752\n",
      "Epoch [1/3], Step [2700/6471], Loss: 2.2887, Perplexity: 9.86176\n",
      "Epoch [1/3], Step [2800/6471], Loss: 2.1581, Perplexity: 8.65518\n",
      "Epoch [1/3], Step [2900/6471], Loss: 3.3335, Perplexity: 28.0362\n",
      "Epoch [1/3], Step [3000/6471], Loss: 2.3372, Perplexity: 10.3526\n",
      "Epoch [1/3], Step [3100/6471], Loss: 2.6785, Perplexity: 14.56329\n",
      "Epoch [1/3], Step [3200/6471], Loss: 2.2687, Perplexity: 9.667348\n",
      "Epoch [1/3], Step [3300/6471], Loss: 2.2054, Perplexity: 9.07401\n",
      "Epoch [1/3], Step [3400/6471], Loss: 2.1939, Perplexity: 8.96993\n",
      "Epoch [1/3], Step [3500/6471], Loss: 2.1201, Perplexity: 8.33214\n",
      "Epoch [1/3], Step [3600/6471], Loss: 2.1258, Perplexity: 8.37957\n",
      "Epoch [1/3], Step [3700/6471], Loss: 2.2778, Perplexity: 9.75531\n",
      "Epoch [1/3], Step [3800/6471], Loss: 2.3679, Perplexity: 10.6754\n",
      "Epoch [1/3], Step [3900/6471], Loss: 2.2136, Perplexity: 9.14870\n",
      "Epoch [1/3], Step [4000/6471], Loss: 2.1896, Perplexity: 8.93146\n",
      "Epoch [1/3], Step [4100/6471], Loss: 2.1492, Perplexity: 8.57783\n",
      "Epoch [1/3], Step [4200/6471], Loss: 1.9846, Perplexity: 7.27602\n",
      "Epoch [1/3], Step [4300/6471], Loss: 2.0029, Perplexity: 7.41036\n",
      "Epoch [1/3], Step [4400/6471], Loss: 2.1299, Perplexity: 8.41371\n",
      "Epoch [1/3], Step [4500/6471], Loss: 2.3565, Perplexity: 10.5536\n",
      "Epoch [1/3], Step [4600/6471], Loss: 2.2340, Perplexity: 9.33700\n",
      "Epoch [1/3], Step [4700/6471], Loss: 2.0757, Perplexity: 7.96991\n",
      "Epoch [1/3], Step [4800/6471], Loss: 2.0713, Perplexity: 7.93513\n",
      "Epoch [1/3], Step [4900/6471], Loss: 2.1761, Perplexity: 8.811823\n",
      "Epoch [1/3], Step [5000/6471], Loss: 2.3573, Perplexity: 10.5624\n",
      "Epoch [1/3], Step [5100/6471], Loss: 2.4751, Perplexity: 11.8826\n",
      "Epoch [1/3], Step [5200/6471], Loss: 2.2175, Perplexity: 9.18440\n",
      "Epoch [1/3], Step [5300/6471], Loss: 2.0885, Perplexity: 8.07264\n",
      "Epoch [1/3], Step [5400/6471], Loss: 2.2929, Perplexity: 9.90351\n",
      "Epoch [1/3], Step [5500/6471], Loss: 2.2975, Perplexity: 9.94974\n",
      "Epoch [1/3], Step [5600/6471], Loss: 2.0748, Perplexity: 7.96312\n",
      "Epoch [1/3], Step [5700/6471], Loss: 2.6062, Perplexity: 13.5477\n",
      "Epoch [1/3], Step [5800/6471], Loss: 2.0324, Perplexity: 7.63259\n",
      "Epoch [1/3], Step [5900/6471], Loss: 2.6791, Perplexity: 14.5725\n",
      "Epoch [1/3], Step [6000/6471], Loss: 2.0456, Perplexity: 7.73362\n",
      "Epoch [1/3], Step [6100/6471], Loss: 2.2800, Perplexity: 9.77695\n",
      "Epoch [1/3], Step [6200/6471], Loss: 2.1936, Perplexity: 8.96700\n",
      "Epoch [1/3], Step [6300/6471], Loss: 2.0258, Perplexity: 7.58208\n",
      "Epoch [1/3], Step [6400/6471], Loss: 1.9505, Perplexity: 7.03207\n",
      "Epoch [2/3], Step [100/6471], Loss: 1.9459, Perplexity: 6.999840\n",
      "Epoch [2/3], Step [200/6471], Loss: 2.0484, Perplexity: 7.75548\n",
      "Epoch [2/3], Step [300/6471], Loss: 2.0522, Perplexity: 7.78525\n",
      "Epoch [2/3], Step [400/6471], Loss: 2.1415, Perplexity: 8.51183\n",
      "Epoch [2/3], Step [500/6471], Loss: 2.0941, Perplexity: 8.11778\n",
      "Epoch [2/3], Step [600/6471], Loss: 2.0163, Perplexity: 7.51022\n",
      "Epoch [2/3], Step [700/6471], Loss: 2.4097, Perplexity: 11.1310\n",
      "Epoch [2/3], Step [800/6471], Loss: 2.1209, Perplexity: 8.33882\n",
      "Epoch [2/3], Step [900/6471], Loss: 1.9338, Perplexity: 6.91576\n",
      "Epoch [2/3], Step [1000/6471], Loss: 1.9940, Perplexity: 7.3448\n",
      "Epoch [2/3], Step [1100/6471], Loss: 2.1250, Perplexity: 8.37326\n",
      "Epoch [2/3], Step [1200/6471], Loss: 2.1388, Perplexity: 8.48947\n",
      "Epoch [2/3], Step [1300/6471], Loss: 2.1379, Perplexity: 8.48185\n",
      "Epoch [2/3], Step [1400/6471], Loss: 2.1014, Perplexity: 8.17771\n",
      "Epoch [2/3], Step [1500/6471], Loss: 2.8840, Perplexity: 17.8849\n",
      "Epoch [2/3], Step [1600/6471], Loss: 2.1524, Perplexity: 8.60525\n",
      "Epoch [2/3], Step [1700/6471], Loss: 2.5116, Perplexity: 12.3245\n",
      "Epoch [2/3], Step [1800/6471], Loss: 2.1776, Perplexity: 8.82513\n",
      "Epoch [2/3], Step [1900/6471], Loss: 2.4289, Perplexity: 11.3464\n",
      "Epoch [2/3], Step [2000/6471], Loss: 2.2201, Perplexity: 9.20799\n",
      "Epoch [2/3], Step [2100/6471], Loss: 1.9558, Perplexity: 7.06988\n",
      "Epoch [2/3], Step [2200/6471], Loss: 2.0501, Perplexity: 7.76875\n",
      "Epoch [2/3], Step [2300/6471], Loss: 2.1334, Perplexity: 8.44359\n",
      "Epoch [2/3], Step [2400/6471], Loss: 1.9247, Perplexity: 6.85317\n",
      "Epoch [2/3], Step [2500/6471], Loss: 2.0204, Perplexity: 7.54152\n",
      "Epoch [2/3], Step [2600/6471], Loss: 2.0139, Perplexity: 7.49234\n",
      "Epoch [2/3], Step [2700/6471], Loss: 2.0344, Perplexity: 7.64755\n",
      "Epoch [2/3], Step [2800/6471], Loss: 2.1922, Perplexity: 8.95514\n",
      "Epoch [2/3], Step [2900/6471], Loss: 1.9721, Perplexity: 7.18587\n",
      "Epoch [2/3], Step [3000/6471], Loss: 2.0792, Perplexity: 7.99797\n",
      "Epoch [2/3], Step [3100/6471], Loss: 2.6730, Perplexity: 14.4833\n",
      "Epoch [2/3], Step [3200/6471], Loss: 2.3353, Perplexity: 10.3330\n",
      "Epoch [2/3], Step [3300/6471], Loss: 2.3383, Perplexity: 10.3635\n",
      "Epoch [2/3], Step [3400/6471], Loss: 2.0824, Perplexity: 8.02404\n",
      "Epoch [2/3], Step [3500/6471], Loss: 2.1204, Perplexity: 8.33435\n",
      "Epoch [2/3], Step [3600/6471], Loss: 2.0208, Perplexity: 7.54462\n",
      "Epoch [2/3], Step [3700/6471], Loss: 1.9250, Perplexity: 6.85501\n",
      "Epoch [2/3], Step [3800/6471], Loss: 2.0925, Perplexity: 8.10484\n",
      "Epoch [2/3], Step [3900/6471], Loss: 1.8873, Perplexity: 6.60137\n",
      "Epoch [2/3], Step [4000/6471], Loss: 2.2126, Perplexity: 9.13913\n",
      "Epoch [2/3], Step [4100/6471], Loss: 2.0380, Perplexity: 7.67544\n",
      "Epoch [2/3], Step [4200/6471], Loss: 1.9758, Perplexity: 7.21210\n",
      "Epoch [2/3], Step [4300/6471], Loss: 2.0553, Perplexity: 7.80903\n",
      "Epoch [2/3], Step [4400/6471], Loss: 2.8423, Perplexity: 17.1549\n",
      "Epoch [2/3], Step [4500/6471], Loss: 1.9747, Perplexity: 7.20462\n",
      "Epoch [2/3], Step [4600/6471], Loss: 1.9695, Perplexity: 7.16744\n",
      "Epoch [2/3], Step [4700/6471], Loss: 2.0570, Perplexity: 7.82264\n",
      "Epoch [2/3], Step [4800/6471], Loss: 2.0154, Perplexity: 7.50349\n",
      "Epoch [2/3], Step [4900/6471], Loss: 1.9877, Perplexity: 7.29866\n",
      "Epoch [2/3], Step [5000/6471], Loss: 2.0568, Perplexity: 7.82127\n",
      "Epoch [2/3], Step [5100/6471], Loss: 2.0402, Perplexity: 7.69214\n",
      "Epoch [2/3], Step [5200/6471], Loss: 2.1977, Perplexity: 9.00398\n",
      "Epoch [2/3], Step [5300/6471], Loss: 2.0379, Perplexity: 7.67460\n",
      "Epoch [2/3], Step [5400/6471], Loss: 1.9436, Perplexity: 6.98355\n",
      "Epoch [2/3], Step [5500/6471], Loss: 2.0471, Perplexity: 7.74531\n",
      "Epoch [2/3], Step [5600/6471], Loss: 1.9903, Perplexity: 7.31787\n",
      "Epoch [2/3], Step [5700/6471], Loss: 1.9626, Perplexity: 7.11762\n",
      "Epoch [2/3], Step [5800/6471], Loss: 2.1935, Perplexity: 8.96636\n",
      "Epoch [2/3], Step [5900/6471], Loss: 2.3749, Perplexity: 10.7499\n",
      "Epoch [2/3], Step [6000/6471], Loss: 1.8147, Perplexity: 6.13945\n",
      "Epoch [2/3], Step [6100/6471], Loss: 1.9598, Perplexity: 7.09827\n",
      "Epoch [2/3], Step [6200/6471], Loss: 1.8494, Perplexity: 6.35621\n",
      "Epoch [2/3], Step [6300/6471], Loss: 1.9468, Perplexity: 7.00607\n",
      "Epoch [2/3], Step [6400/6471], Loss: 1.9710, Perplexity: 7.17813\n",
      "Epoch [3/3], Step [100/6471], Loss: 2.1692, Perplexity: 8.751403\n",
      "Epoch [3/3], Step [200/6471], Loss: 2.1976, Perplexity: 9.00306\n",
      "Epoch [3/3], Step [300/6471], Loss: 2.9441, Perplexity: 18.9935\n",
      "Epoch [3/3], Step [400/6471], Loss: 1.9452, Perplexity: 6.99499\n",
      "Epoch [3/3], Step [500/6471], Loss: 2.3667, Perplexity: 10.6623\n",
      "Epoch [3/3], Step [600/6471], Loss: 2.2191, Perplexity: 9.19956\n",
      "Epoch [3/3], Step [700/6471], Loss: 1.9603, Perplexity: 7.10138\n",
      "Epoch [3/3], Step [800/6471], Loss: 1.9106, Perplexity: 6.75717\n",
      "Epoch [3/3], Step [900/6471], Loss: 2.0054, Perplexity: 7.42871\n",
      "Epoch [3/3], Step [1000/6471], Loss: 2.0993, Perplexity: 8.1606\n",
      "Epoch [3/3], Step [1100/6471], Loss: 1.7770, Perplexity: 5.91210\n",
      "Epoch [3/3], Step [1200/6471], Loss: 1.7912, Perplexity: 5.99698\n",
      "Epoch [3/3], Step [1300/6471], Loss: 2.2839, Perplexity: 9.81472\n",
      "Epoch [3/3], Step [1400/6471], Loss: 2.0265, Perplexity: 7.58785\n",
      "Epoch [3/3], Step [1500/6471], Loss: 1.9766, Perplexity: 7.21845\n",
      "Epoch [3/3], Step [1600/6471], Loss: 2.2526, Perplexity: 9.51252\n",
      "Epoch [3/3], Step [1700/6471], Loss: 2.0320, Perplexity: 7.62903\n",
      "Epoch [3/3], Step [1800/6471], Loss: 2.1408, Perplexity: 8.50653\n",
      "Epoch [3/3], Step [1900/6471], Loss: 2.2631, Perplexity: 9.61279\n",
      "Epoch [3/3], Step [2000/6471], Loss: 2.1479, Perplexity: 8.56661\n",
      "Epoch [3/3], Step [2100/6471], Loss: 2.1826, Perplexity: 8.86913\n",
      "Epoch [3/3], Step [2200/6471], Loss: 1.9104, Perplexity: 6.75596\n",
      "Epoch [3/3], Step [2300/6471], Loss: 2.0760, Perplexity: 7.97228\n",
      "Epoch [3/3], Step [2400/6471], Loss: 1.9914, Perplexity: 7.32573\n",
      "Epoch [3/3], Step [2500/6471], Loss: 2.0186, Perplexity: 7.52800\n",
      "Epoch [3/3], Step [2600/6471], Loss: 1.9026, Perplexity: 6.703076\n",
      "Epoch [3/3], Step [2700/6471], Loss: 1.9241, Perplexity: 6.84936\n",
      "Epoch [3/3], Step [2800/6471], Loss: 2.3776, Perplexity: 10.7785\n",
      "Epoch [3/3], Step [2900/6471], Loss: 1.8283, Perplexity: 6.22336\n",
      "Epoch [3/3], Step [3000/6471], Loss: 1.8727, Perplexity: 6.50561\n",
      "Epoch [3/3], Step [3100/6471], Loss: 2.0703, Perplexity: 7.92716\n",
      "Epoch [3/3], Step [3200/6471], Loss: 2.2600, Perplexity: 9.58300\n",
      "Epoch [3/3], Step [3300/6471], Loss: 1.9387, Perplexity: 6.94951\n",
      "Epoch [3/3], Step [3400/6471], Loss: 1.9027, Perplexity: 6.70380\n",
      "Epoch [3/3], Step [3500/6471], Loss: 1.9273, Perplexity: 6.87129\n",
      "Epoch [3/3], Step [3600/6471], Loss: 1.9621, Perplexity: 7.11428\n",
      "Epoch [3/3], Step [3700/6471], Loss: 1.9711, Perplexity: 7.17874\n",
      "Epoch [3/3], Step [3800/6471], Loss: 1.9006, Perplexity: 6.68963\n",
      "Epoch [3/3], Step [3900/6471], Loss: 2.0369, Perplexity: 7.66669\n",
      "Epoch [3/3], Step [4000/6471], Loss: 2.0402, Perplexity: 7.69257\n",
      "Epoch [3/3], Step [4100/6471], Loss: 2.0529, Perplexity: 7.79024\n",
      "Epoch [3/3], Step [4200/6471], Loss: 1.9150, Perplexity: 6.78674\n",
      "Epoch [3/3], Step [4300/6471], Loss: 2.0615, Perplexity: 7.85757\n",
      "Epoch [3/3], Step [4400/6471], Loss: 2.0151, Perplexity: 7.50168\n",
      "Epoch [3/3], Step [4500/6471], Loss: 1.9345, Perplexity: 6.92092\n",
      "Epoch [3/3], Step [4600/6471], Loss: 1.7872, Perplexity: 5.97252\n",
      "Epoch [3/3], Step [4700/6471], Loss: 2.0880, Perplexity: 8.06866\n",
      "Epoch [3/3], Step [4800/6471], Loss: 2.0411, Perplexity: 7.69937\n",
      "Epoch [3/3], Step [4900/6471], Loss: 2.2034, Perplexity: 9.05533\n",
      "Epoch [3/3], Step [5000/6471], Loss: 1.9997, Perplexity: 7.38670\n",
      "Epoch [3/3], Step [5100/6471], Loss: 2.2578, Perplexity: 9.56162\n",
      "Epoch [3/3], Step [5200/6471], Loss: 2.0629, Perplexity: 7.86877\n",
      "Epoch [3/3], Step [5300/6471], Loss: 2.0425, Perplexity: 7.70990\n",
      "Epoch [3/3], Step [5400/6471], Loss: 1.9082, Perplexity: 6.74071\n",
      "Epoch [3/3], Step [5500/6471], Loss: 2.7147, Perplexity: 15.1006\n",
      "Epoch [3/3], Step [5600/6471], Loss: 1.7900, Perplexity: 5.98968\n",
      "Epoch [3/3], Step [5700/6471], Loss: 1.9707, Perplexity: 7.17604\n",
      "Epoch [3/3], Step [5800/6471], Loss: 1.8874, Perplexity: 6.60220\n",
      "Epoch [3/3], Step [5900/6471], Loss: 1.7781, Perplexity: 5.91852\n",
      "Epoch [3/3], Step [6000/6471], Loss: 1.9268, Perplexity: 6.86784\n",
      "Epoch [3/3], Step [6100/6471], Loss: 2.0432, Perplexity: 7.71537\n",
      "Epoch [3/3], Step [6200/6471], Loss: 1.7640, Perplexity: 5.83599\n",
      "Epoch [3/3], Step [6300/6471], Loss: 2.1313, Perplexity: 8.42563\n",
      "Epoch [3/3], Step [6400/6471], Loss: 1.9470, Perplexity: 7.00786\n",
      "Epoch [3/3], Step [6469/6471], Loss: 2.0107, Perplexity: 7.46877"
     ]
    }
   ],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Open the training log file.\n",
    "f = open(log_file, 'w')\n",
    "\n",
    "old_time = time.time()\n",
    "response = requests.request(\"GET\", \n",
    "                            \"http://metadata.google.internal/computeMetadata/v1/instance/attributes/keep_alive_token\", \n",
    "                            headers={\"Metadata-Flavor\":\"Google\"})\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    \n",
    "    for i_step in range(1, total_step+1):\n",
    "        \n",
    "        if time.time() - old_time > 60:\n",
    "            old_time = time.time()\n",
    "            requests.request(\"POST\", \n",
    "                             \"https://nebula.udacity.com/api/v1/remote/keep-alive\", \n",
    "                             headers={'Authorization': \"STAR \" + response.text})\n",
    "        \n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "        \n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "        \n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        # Pass the inputs through the CNN-RNN model.\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        # Calculate the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "        \n",
    "        # Backward pass.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the parameters in the optimizer.\n",
    "        optimizer.step()\n",
    "            \n",
    "        # Get training statistics.\n",
    "        stats = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Perplexity: %5.4f' % (epoch, num_epochs, i_step, total_step, loss.item(), np.exp(loss.item()))\n",
    "        \n",
    "        # Print training statistics (on same line).\n",
    "        print('\\r' + stats, end=\"\")\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + '\\n')\n",
    "        f.flush()\n",
    "        \n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print('\\r' + stats)\n",
    "            \n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(decoder.state_dict(), os.path.join('./models', 'decoder-%d.pkl' % epoch))\n",
    "        torch.save(encoder.state_dict(), os.path.join('./models', 'encoder-%d.pkl' % epoch))\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='step3'></a>\n",
    "## Step 3: (Optional) Validate your Model\n",
    "\n",
    "To assess potential overfitting, one approach is to assess performance on a validation set.  If you decide to do this **optional** task, you are required to first complete all of the steps in the next notebook in the sequence (**3_Inference.ipynb**); as part of that notebook, you will write and test code (specifically, the `sample` method in the `DecoderRNN` class) that uses your RNN decoder to generate captions.  That code will prove incredibly useful here. \n",
    "\n",
    "If you decide to validate your model, please do not edit the data loader in **data_loader.py**.  Instead, create a new file named **data_loader_val.py** containing the code for obtaining the data loader for the validation data.  You can access:\n",
    "- the validation images at filepath `'/opt/cocoapi/images/train2014/'`, and\n",
    "- the validation image caption annotation file at filepath `'/opt/cocoapi/annotations/captions_val2014.json'`.\n",
    "\n",
    "The suggested approach to validating your model involves creating a json file such as [this one](https://github.com/cocodataset/cocoapi/blob/master/results/captions_val2014_fakecap_results.json) containing your model's predicted captions for the validation images.  Then, you can write your own script or use one that you [find online](https://github.com/tylin/coco-caption) to calculate the BLEU score of your model.  You can read more about the BLEU score, along with other evaluation metrics (such as TEOR and Cider) in section 4.1 of [this paper](https://arxiv.org/pdf/1411.4555.pdf).  For more information about how to use the annotation file, check out the [website](http://cocodataset.org/#download) for the COCO dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) TODO: Validate your model."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
